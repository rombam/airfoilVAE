{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational Auto-Encoder (VAE) PyTorch implementation\n",
    "Evolution of the auto-encoder neural network to reduce dimensionality of an airfoil defined by 30 coordinates.  \n",
    "Papers:\n",
    "- Larsen et al.: \"Autoencoding beyond pixels using a learned similarity metric\" - https://arxiv.org/abs/1512.09300\n",
    "- Wang et al.: \"Airfoil GAN: Encoding and Synthesizing Airfoils forAerodynamic-aware Shape Optimization\" - https://arxiv.org/abs/2101.04757"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from types_ import *\n",
    "\n",
    "plt.style.use('seaborn-whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "CUDA version: 10.2\n"
     ]
    }
   ],
   "source": [
    "# Library options\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "# Get CPU or GPU device for NN\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def airfoil_info(airfoil_df, plot_airfoil, mach=0.1, reynolds=1e5):\n",
    "    \"\"\"\n",
    "    Returns a plot of a NACA airfoil's shape, Cl and Cd between alpha = -10 and alpha = 10 degrees. \n",
    "    Assumes 15 points for upper surface and 15 points for lower surface.\n",
    "    Inputs:\n",
    "        - airfoil_df: pandas dataframe with airfoil data\n",
    "        - plot_airfoil: index that specifies which airfoil to plot\n",
    "    Outputs:\n",
    "        - Plot of airfoil shape, Cl and Cd\n",
    "    \"\"\"\n",
    "    # X coordinates\n",
    "    x = [0.5*(1-np.cos(ang)) for ang in np.linspace(0,np.pi,17)]\n",
    "    aux_x = list(reversed([0.5*(1-np.cos(ang)) for ang in np.linspace(0,np.pi,17)[1:16]]))\n",
    "    [x.append(i) for i in aux_x]\n",
    "    x.append(0)\n",
    "    \n",
    "    first_coord_list = airfoil_df.loc[(airfoil_df['MachNumber'] == mach) & (airfoil_df['ReynoldsNumber'] == reynolds)]['yU_1'].unique()\n",
    "    plot_airfoil_df = airfoil_df.loc[(airfoil_df['MachNumber'] == mach) & (airfoil_df['ReynoldsNumber'] == reynolds) & (airfoil_df['yU_1']==first_coord_list[plot_airfoil])]\n",
    "    \n",
    "    # Y coordinates\n",
    "    y = []\n",
    "    origin = (plot_airfoil_df.iloc[1][0]+plot_airfoil_df.iloc[1][15])/2\n",
    "    y.append(origin)\n",
    "    [y.append(j) for j in plot_airfoil_df.iloc[1][0:15].values.tolist()]\n",
    "    y.append(0)\n",
    "    aux_y = list(reversed(plot_airfoil_df.iloc[1][15:30].values.tolist()))\n",
    "    [y.append(k) for k in aux_y]\n",
    "    y.append(origin)\n",
    "    \n",
    "    # Cl, Cd, alphas\n",
    "    Cl = plot_airfoil_df['Cl'].values.tolist()[0:21]\n",
    "    Cd = plot_airfoil_df['Cd'].values.tolist()[0:21]\n",
    "    alphas = np.linspace(-10,10,len(Cl))\n",
    "    \n",
    "    # Airfoil plot\n",
    "    plot1 = plt.subplot2grid((2,2), (0,0), colspan = 2)\n",
    "    plot2 = plt.subplot2grid((2,2), (1,0))\n",
    "    plot3 = plt.subplot2grid((2,2), (1,1))\n",
    "    \n",
    "    plot1.plot(x, y)\n",
    "    plot1.set_xlim([-0.1,1.1])\n",
    "    plot1.set_ylim([np.min(y)-0.2*np.abs(np.min(y)),np.max(y)+0.2*np.abs(np.max(y))])\n",
    "    plot1.set_ylabel('$y/c$')\n",
    "    plot1.set_xlabel('$x/c$') \n",
    "    plot1.set_title('Airfoil plot', fontsize=16)\n",
    "    \n",
    "    plot2.plot(alphas, Cl)\n",
    "    plot2.set_xlim([-10,10])\n",
    "    plot2.set_ylim([np.min(Cl)-0.1*np.abs(np.min(Cl)),np.max(Cl)+0.1*np.abs(np.max(Cl))])\n",
    "    plot2.set_ylabel('$C_L$')\n",
    "    plot2.set_xlabel('$\\\\alpha$ [$^\\\\circ$]') \n",
    "    \n",
    "    plot3.plot(alphas, Cd)\n",
    "    plot3.set_xlim([-10,10])\n",
    "    plot3.set_ylim([np.min(Cd)-0.1*np.abs(np.min(Cd)),np.max(Cd)+0.1*np.abs(np.max(Cd))])\n",
    "    plot3.set_ylabel('$C_D$')\n",
    "    plot3.set_xlabel('$\\\\alpha$ [$^\\\\circ$]') \n",
    " \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "def airfoil_plot(airfoil_coords, fig=None, label=None):\n",
    "    \"\"\"\n",
    "    Returns a plot of an airfoil. Used to visualize output of the optimizer. \n",
    "    Assumes 15 points for upper surface and 15 points for lower surface, with cosine spacing.\n",
    "    Inputs:\n",
    "        - airfoil_coords: pandas DataFrame with airfoil coordinates and other parameters\n",
    "    Outputs:\n",
    "        - Plot of airfoil shape\n",
    "    \"\"\"\n",
    "    if fig==None:\n",
    "        fig = plt.subplot2grid((1,3), (0,0), colspan = 3)\n",
    "    # X coordinates\n",
    "    x = [0.5*(1-np.cos(ang)) for ang in np.linspace(0,np.pi,17)]\n",
    "    aux_x = list(reversed([0.5*(1-np.cos(ang)) for ang in np.linspace(0,np.pi,17)[1:16]]))\n",
    "    [x.append(i) for i in aux_x]\n",
    "    x.append(0)\n",
    "    \n",
    "    # Y coordinates\n",
    "    y = []\n",
    "    origin = (airfoil_coords.iloc[0][0]+airfoil_coords.iloc[0][15])/2\n",
    "    y.append(origin)\n",
    "    [y.append(j) for j in airfoil_coords.iloc[0][0:15].values.tolist()]\n",
    "    y.append(0)\n",
    "    aux_y = list(reversed(airfoil_coords.iloc[0][15:30].values.tolist()))\n",
    "    [y.append(k) for k in aux_y]\n",
    "    y.append(origin)\n",
    "    \n",
    "    # Airfoil plot     \n",
    "    fig.plot(x, y, label = label)\n",
    "    fig.set_xlim([-0.1,1.1])\n",
    "    fig.set_ylim([-0.2,0.3])\n",
    "    fig.set_ylabel('$y/c$')\n",
    "    fig.set_xlabel('$x/c$') \n",
    "    fig.set_title('Airfoil plot', fontsize=16)\n",
    "    fig.legend()\n",
    "    if fig==None:\n",
    "        plt.show()\n",
    "    return\n",
    "\n",
    "\n",
    "def torch_test_split(X, y, test_size=0.2, seed=1234):\n",
    "    \"\"\"\n",
    "    Returns a train and test set in PyTorch tensor format from a numpy array dataset.\n",
    "    Inputs:\n",
    "        - X: numpy array with input data. Each row is a training/testing sample and each column is a feature.\n",
    "        - y: numpy array with output data. Each row is a training/testing sample and each column is an output.\n",
    "        - test_size: proportion of the dataset to be used as test set.\n",
    "        - seed: random seed for reproducibility.\n",
    "    Outputs:\n",
    "        - training_data: PyTorch tensor with training data.\n",
    "        - test_data: PyTorch tensor with test data.\n",
    "    \"\"\"\n",
    "    X_train_0, X_test_0, y_train_0, y_test_0 = train_test_split(X, y, test_size=test_size, random_state=seed)\n",
    "    X_train = torch.from_numpy(X_train_0).float()\n",
    "    X_test = torch.from_numpy(X_test_0).float()\n",
    "    y_train = torch.from_numpy(y_train_0).float()\n",
    "    y_test = torch.from_numpy(y_test_0).float()\n",
    "    training_data = []\n",
    "    testing_data = []\n",
    "    for i in range(len(X_train)):\n",
    "        training_data.append((X_train[i], y_train[i]))\n",
    "    for i in range(len(X_test)):\n",
    "        testing_data.append((X_test[i], y_test[i]))\n",
    "    return training_data, testing_data\n",
    "\n",
    "def normalize_data (data, scaler):\n",
    "    \"\"\"\n",
    "    Normalizes neural network inputs and outputs.\n",
    "    Inputs:\n",
    "        - data: data to be normalized. [np.array / pd.DataFrame]\n",
    "        - scaler: pre-fitted scaler object.\n",
    "    Outputs:\n",
    "        - normalized data. [pd.DataFrame]\n",
    "    \"\"\"\n",
    "    if type(data) == pd.DataFrame:\n",
    "        data = data.to_numpy().reshape(-1,scaler.n_features_in_)\n",
    "    elif type(data) == np.ndarray:\n",
    "        data = data.reshape(-1,scaler.n_features_in_)\n",
    "    else:\n",
    "        raise(TypeError('Input data must be either a pd.DataFrame or a np.ndarray'))\n",
    "    norm_data = pd.DataFrame(data = scaler.transform(data), columns = scaler.feature_names_in_)\n",
    "    return norm_data\n",
    "\n",
    "def denormalize_data (data, scaler):\n",
    "    \"\"\"\n",
    "    Denormalizes neural network inputs and outputs.\n",
    "    Inputs:\n",
    "        - data: data to be denormalized. [np.array / pd.DataFrame]\n",
    "        - scaler: pre-fitted scaler object.\n",
    "    Outputs:\n",
    "        - denormalized data. [pd.DataFrame]\n",
    "    \"\"\"\n",
    "    if type(data) == pd.DataFrame:\n",
    "        data = data.to_numpy().reshape(-1,scaler.n_features_in_)\n",
    "    elif type(data) == np.ndarray:\n",
    "        data = data.reshape(-1,scaler.n_features_in_)\n",
    "    else:\n",
    "        raise(TypeError('Input data must be either a pd.DataFrame or a np.ndarray'))\n",
    "    denorm_data = pd.DataFrame(data = scaler.inverse_transform(data), columns = scaler.feature_names_in_)\n",
    "    return denorm_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yU_1</th>\n",
       "      <th>yU_2</th>\n",
       "      <th>yU_3</th>\n",
       "      <th>yU_4</th>\n",
       "      <th>yU_5</th>\n",
       "      <th>yU_6</th>\n",
       "      <th>yU_7</th>\n",
       "      <th>yU_8</th>\n",
       "      <th>yU_9</th>\n",
       "      <th>yU_10</th>\n",
       "      <th>...</th>\n",
       "      <th>yL_12</th>\n",
       "      <th>yL_13</th>\n",
       "      <th>yL_14</th>\n",
       "      <th>yL_15</th>\n",
       "      <th>ReynoldsNumber</th>\n",
       "      <th>MachNumber</th>\n",
       "      <th>alpha</th>\n",
       "      <th>Cl</th>\n",
       "      <th>Cd</th>\n",
       "      <th>Cm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.006923</td>\n",
       "      <td>0.013103</td>\n",
       "      <td>0.018233</td>\n",
       "      <td>0.022013</td>\n",
       "      <td>0.024229</td>\n",
       "      <td>0.024823</td>\n",
       "      <td>0.023923</td>\n",
       "      <td>0.021796</td>\n",
       "      <td>0.018781</td>\n",
       "      <td>0.015248</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007926</td>\n",
       "      <td>-0.004725</td>\n",
       "      <td>-0.002193</td>\n",
       "      <td>-0.000563</td>\n",
       "      <td>100000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-10</td>\n",
       "      <td>-0.334</td>\n",
       "      <td>0.16140</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>0.013846</td>\n",
       "      <td>0.026207</td>\n",
       "      <td>0.036466</td>\n",
       "      <td>0.044027</td>\n",
       "      <td>0.048457</td>\n",
       "      <td>0.049647</td>\n",
       "      <td>0.047845</td>\n",
       "      <td>0.043592</td>\n",
       "      <td>0.037561</td>\n",
       "      <td>0.030495</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015853</td>\n",
       "      <td>-0.009451</td>\n",
       "      <td>-0.004386</td>\n",
       "      <td>-0.001126</td>\n",
       "      <td>100000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-10</td>\n",
       "      <td>-0.800</td>\n",
       "      <td>0.07872</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>0.020769</td>\n",
       "      <td>0.039310</td>\n",
       "      <td>0.054699</td>\n",
       "      <td>0.066040</td>\n",
       "      <td>0.072686</td>\n",
       "      <td>0.074470</td>\n",
       "      <td>0.071768</td>\n",
       "      <td>0.065388</td>\n",
       "      <td>0.056342</td>\n",
       "      <td>0.045743</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023779</td>\n",
       "      <td>-0.014176</td>\n",
       "      <td>-0.006579</td>\n",
       "      <td>-0.001690</td>\n",
       "      <td>100000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-10</td>\n",
       "      <td>-1.051</td>\n",
       "      <td>0.03804</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>945</th>\n",
       "      <td>0.027692</td>\n",
       "      <td>0.052414</td>\n",
       "      <td>0.072932</td>\n",
       "      <td>0.088053</td>\n",
       "      <td>0.096914</td>\n",
       "      <td>0.099294</td>\n",
       "      <td>0.095691</td>\n",
       "      <td>0.087184</td>\n",
       "      <td>0.075122</td>\n",
       "      <td>0.060990</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.031706</td>\n",
       "      <td>-0.018901</td>\n",
       "      <td>-0.008772</td>\n",
       "      <td>-0.002253</td>\n",
       "      <td>100000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-10</td>\n",
       "      <td>-1.146</td>\n",
       "      <td>0.03410</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1260</th>\n",
       "      <td>0.034615</td>\n",
       "      <td>0.065517</td>\n",
       "      <td>0.091165</td>\n",
       "      <td>0.110067</td>\n",
       "      <td>0.121143</td>\n",
       "      <td>0.124117</td>\n",
       "      <td>0.119614</td>\n",
       "      <td>0.108980</td>\n",
       "      <td>0.093903</td>\n",
       "      <td>0.076238</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039632</td>\n",
       "      <td>-0.023626</td>\n",
       "      <td>-0.010965</td>\n",
       "      <td>-0.002816</td>\n",
       "      <td>100000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-10</td>\n",
       "      <td>-1.188</td>\n",
       "      <td>0.03644</td>\n",
       "      <td>0.013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          yU_1      yU_2      yU_3      yU_4      yU_5      yU_6      yU_7  \\\n",
       "0     0.006923  0.013103  0.018233  0.022013  0.024229  0.024823  0.023923   \n",
       "315   0.013846  0.026207  0.036466  0.044027  0.048457  0.049647  0.047845   \n",
       "630   0.020769  0.039310  0.054699  0.066040  0.072686  0.074470  0.071768   \n",
       "945   0.027692  0.052414  0.072932  0.088053  0.096914  0.099294  0.095691   \n",
       "1260  0.034615  0.065517  0.091165  0.110067  0.121143  0.124117  0.119614   \n",
       "\n",
       "          yU_8      yU_9     yU_10  ...     yL_12     yL_13     yL_14  \\\n",
       "0     0.021796  0.018781  0.015248  ... -0.007926 -0.004725 -0.002193   \n",
       "315   0.043592  0.037561  0.030495  ... -0.015853 -0.009451 -0.004386   \n",
       "630   0.065388  0.056342  0.045743  ... -0.023779 -0.014176 -0.006579   \n",
       "945   0.087184  0.075122  0.060990  ... -0.031706 -0.018901 -0.008772   \n",
       "1260  0.108980  0.093903  0.076238  ... -0.039632 -0.023626 -0.010965   \n",
       "\n",
       "         yL_15  ReynoldsNumber  MachNumber  alpha     Cl       Cd     Cm  \n",
       "0    -0.000563          100000         0.1    -10 -0.334  0.16140  0.001  \n",
       "315  -0.001126          100000         0.1    -10 -0.800  0.07872  0.003  \n",
       "630  -0.001690          100000         0.1    -10 -1.051  0.03804  0.008  \n",
       "945  -0.002253          100000         0.1    -10 -1.146  0.03410  0.011  \n",
       "1260 -0.002816          100000         0.1    -10 -1.188  0.03644  0.013  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define input dataset (.csv) name and path\n",
    "data_folder = './data/'\n",
    "dataset_name = 'NACA4Digit_Dataset15Point.csv'\n",
    "\n",
    "# Import dataset\n",
    "airfoil_df = pd.read_csv(data_folder + dataset_name)\n",
    "airfoil_df = airfoil_df.drop('Unnamed: 0', axis=1)    # Remove first column, counter\n",
    "airfoil_df = airfoil_df.drop_duplicates(subset=['yU_1'], keep='first')    # Remove duplicate airfoil coordinates\n",
    "\n",
    "# Get rid of duplicates\n",
    "# airfoil_df = airfoil_df.drop_duplicates(subset=['yU_1', 'yL_1', 'ReynoldsNumber', 'MachNumber', 'alpha', 'Cl','Cd','Cm'])\n",
    "\n",
    "airfoil_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Variational Autoencoder model\n",
    "In this section, an MLP based variational encoder-decoder network will be created and trained to process airfoil coordinates and recreate them from a set of latent variables characterized by their mean $\\mu$ and standard deviation $\\sigma$.\n",
    "\n",
    "**Inputs**\n",
    "- Upper surface coordinates (15)\n",
    "- Lower surface coordinates (15)\n",
    "\n",
    "**Outputs**\n",
    "- Approximately the same coordinates (network will be trained to do so)\n",
    "\n",
    "There will be a layer in the middle that will encode the _latent feature_ distributions of the set. This is akin to a parameterization method, with arbitrary parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([32, 30]) torch.float32\n",
      "Shape of y: torch.Size([32, 30]) torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\.conda\\envs\\pytorchML\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Data scaler fitting\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(airfoil_df)\n",
    "\n",
    "# Assemble a DataFrame with all the minimum and maximum values of each column\n",
    "# For normalization and de-normalization. Gives an idea of the bounds.\n",
    "scaler_bounds = pd.DataFrame(data = np.stack([scaler.feature_names_in_, scaler.data_min_, scaler.data_max_], axis=1), columns=['property', 'min', 'max'])\n",
    "\n",
    "# Data normalization\n",
    "airfoil_df_norm = normalize_data(airfoil_df, scaler)\n",
    "\n",
    "# Input and \"output\" features\n",
    "# Input and output features are both the same for this dataset.\n",
    "X = airfoil_df_norm.drop(['Cl', 'Cd', 'Cm', 'ReynoldsNumber', 'MachNumber', 'alpha'], axis=1).values\n",
    "\n",
    "# Data tensors\n",
    "training_data, test_data = torch_test_split(X, X, test_size=0.2)\n",
    "\n",
    "# Data loaders\n",
    "batch_size = 32\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape} {y.dtype}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Creating models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAE(\n",
      "  (encoder): Sequential(\n",
      "    (0): Linear(in_features=30, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Sequential(\n",
      "      (0): Linear(in_features=256, out_features=128, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): Linear(in_features=128, out_features=32, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (fc_mu): Linear(in_features=32, out_features=3, bias=True)\n",
      "  (fc_var): Linear(in_features=32, out_features=3, bias=True)\n",
      "  (decoder_input): Linear(in_features=3, out_features=32, bias=True)\n",
      "  (decoder): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=32, out_features=128, bias=True)\n",
      "      (1): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Linear(in_features=128, out_features=256, bias=True)\n",
      "      (1): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (2): Linear(in_features=256, out_features=30, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "device = 'cuda'\n",
    "latent_dim = 3\n",
    "in_channels = 30\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    \"\"\"\n",
    "    Variational autoencoder neural network based on MLP layers. \n",
    "    Default widths = [128, 64, 32, num_features x 2] for the encoder and [32, 32, 64, 128] for the decoder.\n",
    "    Middle layer: mu and sigma for each latent variable.\n",
    "    Adapted from the base VAE in https://github.com/AntixK/PyTorch-VAE.\n",
    "    Activation : ReLU.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 in_channels: int,\n",
    "                 latent_dim: int,\n",
    "                 hidden_dims: List = None,\n",
    "                 **kwargs) -> None:\n",
    "        super(VAE, self).__init__()\n",
    "        \n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        if hidden_dims is None:\n",
    "            hidden_dims = [256, 128, 32]\n",
    "\n",
    "        # Build Encoder\n",
    "        modules = []\n",
    "        modules.append(nn.Linear(in_channels, hidden_dims[0]))\n",
    "        modules.append(nn.ReLU())\n",
    "        for i in range(len(hidden_dims) - 1):\n",
    "            modules.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Linear(hidden_dims[i], hidden_dims[i+1]),\n",
    "                    nn.ReLU())\n",
    "            )\n",
    "\n",
    "        self.encoder = nn.Sequential(*modules)\n",
    "        self.fc_mu = nn.Linear(hidden_dims[-1], latent_dim)\n",
    "        self.fc_var = nn.Linear(hidden_dims[-1], latent_dim)\n",
    "\n",
    "        # Build Decoder\n",
    "        modules = []\n",
    "        self.decoder_input = nn.Linear(latent_dim, hidden_dims[-1])\n",
    "        hidden_dims.reverse()\n",
    "        for i in range(len(hidden_dims) - 1):\n",
    "            modules.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Linear(hidden_dims[i], hidden_dims[i+1]),\n",
    "                    nn.LeakyReLU())\n",
    "            )\n",
    "        modules.append(nn.Linear(hidden_dims[-1], in_channels))\n",
    "        \n",
    "        self.decoder = nn.Sequential(*modules)\n",
    "    \n",
    "    def encode(self, x):\n",
    "        \"\"\"\n",
    "        Encodes the input by passing through the encoder network\n",
    "        and returns the latent codes.\n",
    "        :param input: (Tensor) Input tensor to encoder [N x D_in]\n",
    "        :return: (Tensor) List of latent codes\n",
    "        \"\"\"\n",
    "        encoded = self.encoder(x)\n",
    "        mu = self.fc_mu(encoded)\n",
    "        log_var = self.fc_var(encoded)\n",
    "        return [mu, log_var]\n",
    "    \n",
    "    def decode(self, z):\n",
    "        \"\"\"\n",
    "        Maps the given latent codes\n",
    "        onto the coordinate space.\n",
    "        :param z: (Tensor) [B x D_latent]\n",
    "        :return: (Tensor) [B x D_out]\n",
    "        \"\"\"\n",
    "        decoded = self.decoder_input(z)\n",
    "        decoded = self.decoder(decoded)\n",
    "        return decoded\n",
    "    \n",
    "    def reparameterize(self, mu: Tensor, logvar: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Reparameterization trick to sample from N(mu, var) from\n",
    "        N(0,1).\n",
    "        :param mu: (Tensor) Mean of the latent Gaussian [B x D_latent]\n",
    "        :param logvar: (Tensor) Standard deviation of the latent Gaussian [B x D_latent]\n",
    "        :return: (Tensor) [B x D_latent]\n",
    "        \"\"\"\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return eps * std + mu\n",
    "    \n",
    "    def forward(self, input: Tensor, **kwargs) -> List[Tensor]:\n",
    "        mu, log_var = self.encode(input)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        return  [self.decode(z), input, mu, log_var]\n",
    "    \n",
    "    def loss_function(self,\n",
    "                      pred,\n",
    "                      **kwargs) -> dict:\n",
    "        \"\"\"\n",
    "        Computes the VAE loss function.\n",
    "        KL(N(\\mu, \\sigma), N(0, 1)) = \\log \\frac{1}{\\sigma} + \\frac{\\sigma^2 + \\mu^2}{2} - \\frac{1}{2}\n",
    "        :param args:\n",
    "        :param kwargs:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        \n",
    "        recons = pred[0]\n",
    "        input = pred[1]\n",
    "        mu = pred[2]\n",
    "        log_var = pred[3]\n",
    "\n",
    "        #kld_weight = kwargs['M_N'] # Account for the minibatch samples from the dataset\n",
    "        kld_weight = 1.0\n",
    "        # recons_loss = nn.functional.mse_loss(recons, input)\n",
    "        recon_loss_criterion = nn.MSELoss() #Reconstruction Loss\n",
    "        recon_loss = recon_loss_criterion(recons,input)\n",
    "        #recons_loss = nn.functional.mse_loss(recons, input)\n",
    "        \n",
    "        kld_loss = torch.mean(-0.5 * torch.sum(1 + log_var - mu ** 2 - log_var.exp(), dim = 1), dim = 0)\n",
    "\n",
    "        loss = recon_loss + kld_weight * kld_loss\n",
    "        return loss\n",
    "\n",
    "model = VAE(in_channels = in_channels,\n",
    "            latent_dim = latent_dim).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AirfoilVAE(\n",
      "  (encoder): Sequential(\n",
      "    (0): Linear(in_features=30, out_features=512, bias=True)\n",
      "    (1): ELU(alpha=1.0)\n",
      "    (2): Sequential(\n",
      "      (0): Linear(in_features=512, out_features=256, bias=True)\n",
      "      (1): ELU(alpha=1.0)\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): Linear(in_features=256, out_features=128, bias=True)\n",
      "      (1): ELU(alpha=1.0)\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): Linear(in_features=128, out_features=64, bias=True)\n",
      "      (1): ELU(alpha=1.0)\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=32, bias=True)\n",
      "      (1): ELU(alpha=1.0)\n",
      "    )\n",
      "  )\n",
      "  (fc_mu): Linear(in_features=32, out_features=5, bias=True)\n",
      "  (fc_var): Linear(in_features=32, out_features=5, bias=True)\n",
      "  (decoder_input): Linear(in_features=5, out_features=32, bias=True)\n",
      "  (decoder): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=32, out_features=64, bias=True)\n",
      "      (1): ELU(alpha=1.0)\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=128, bias=True)\n",
      "      (1): ELU(alpha=1.0)\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Linear(in_features=128, out_features=256, bias=True)\n",
      "      (1): ELU(alpha=1.0)\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): Linear(in_features=256, out_features=512, bias=True)\n",
      "      (1): ELU(alpha=1.0)\n",
      "    )\n",
      "    (4): Linear(in_features=512, out_features=30, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "from AirfoilVAE import AirfoilVAE\n",
    "device = 'cuda'\n",
    "latent_dim = 5\n",
    "in_channels = 30\n",
    "hidden_dims = [512, 256, 128, 64, 32]\n",
    "\n",
    "model = AirfoilVAE(in_channels = in_channels,\n",
    "                   latent_dim = latent_dim,\n",
    "                   hidden_dims = hidden_dims).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define train and test functions\n",
    "def train(dataloader, model, loss_fn, optimizer, loss_output = None, recon_output = None, kld_output = None, weight = 1):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, weight = weight)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss['loss'].backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 2 == 0:\n",
    "            losspr, current = loss['loss'].item(), batch * len(X)\n",
    "            print(f\"loss: {losspr:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "            \n",
    "    if loss_output is not None:\n",
    "        try:\n",
    "            loss_output.append(loss['loss'].item())\n",
    "            recon_output.append(loss['Reconstruction_Loss'].item())\n",
    "            kld_output.append(loss['KLD'].item())\n",
    "        except:\n",
    "            loss_output.append(loss)\n",
    "            \n",
    "def test(dataloader, model, loss_fn, weight):\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch, (X, y) in enumerate(dataloader):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model.forward(X)\n",
    "            test_loss += loss_fn(pred, weight = weight)['loss'].item()\n",
    "    test_loss /= num_batches\n",
    "    print(f\"Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.246628  [    0/  408]\n",
      "loss: 0.211032  [   64/  408]\n",
      "loss: 0.140054  [  128/  408]\n",
      "loss: 0.089812  [  192/  408]\n",
      "loss: 0.041887  [  256/  408]\n",
      "loss: 0.064586  [  320/  408]\n",
      "loss: 0.053534  [  288/  408]\n",
      "Avg loss: 0.051931 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.061160  [    0/  408]\n",
      "loss: 0.040652  [   64/  408]\n",
      "loss: 0.047452  [  128/  408]\n",
      "loss: 0.048374  [  192/  408]\n",
      "loss: 0.033602  [  256/  408]\n",
      "loss: 0.048258  [  320/  408]\n",
      "loss: 0.025861  [  288/  408]\n",
      "Avg loss: 0.034182 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.050466  [    0/  408]\n",
      "loss: 0.037410  [   64/  408]\n",
      "loss: 0.034354  [  128/  408]\n",
      "loss: 0.024674  [  192/  408]\n",
      "loss: 0.018129  [  256/  408]\n",
      "loss: 0.027004  [  320/  408]\n",
      "loss: 0.019462  [  288/  408]\n",
      "Avg loss: 0.018132 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.020716  [    0/  408]\n",
      "loss: 0.021693  [   64/  408]\n",
      "loss: 0.022249  [  128/  408]\n",
      "loss: 0.021869  [  192/  408]\n",
      "loss: 0.016314  [  256/  408]\n",
      "loss: 0.024701  [  320/  408]\n",
      "loss: 0.013855  [  288/  408]\n",
      "Avg loss: 0.015996 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.022133  [    0/  408]\n",
      "loss: 0.020641  [   64/  408]\n",
      "loss: 0.021015  [  128/  408]\n",
      "loss: 0.017936  [  192/  408]\n",
      "loss: 0.016613  [  256/  408]\n",
      "loss: 0.022726  [  320/  408]\n",
      "loss: 0.012137  [  288/  408]\n",
      "Avg loss: 0.013961 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.019944  [    0/  408]\n",
      "loss: 0.019702  [   64/  408]\n",
      "loss: 0.018526  [  128/  408]\n",
      "loss: 0.016585  [  192/  408]\n",
      "loss: 0.015543  [  256/  408]\n",
      "loss: 0.020788  [  320/  408]\n",
      "loss: 0.011503  [  288/  408]\n",
      "Avg loss: 0.014107 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.017801  [    0/  408]\n",
      "loss: 0.016811  [   64/  408]\n",
      "loss: 0.017947  [  128/  408]\n",
      "loss: 0.013570  [  192/  408]\n",
      "loss: 0.014259  [  256/  408]\n",
      "loss: 0.018307  [  320/  408]\n",
      "loss: 0.010149  [  288/  408]\n",
      "Avg loss: 0.013361 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.016149  [    0/  408]\n",
      "loss: 0.014512  [   64/  408]\n",
      "loss: 0.015816  [  128/  408]\n",
      "loss: 0.013172  [  192/  408]\n",
      "loss: 0.012430  [  256/  408]\n",
      "loss: 0.018174  [  320/  408]\n",
      "loss: 0.008613  [  288/  408]\n",
      "Avg loss: 0.011749 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.014432  [    0/  408]\n",
      "loss: 0.012913  [   64/  408]\n",
      "loss: 0.013780  [  128/  408]\n",
      "loss: 0.009968  [  192/  408]\n",
      "loss: 0.009244  [  256/  408]\n",
      "loss: 0.012972  [  320/  408]\n",
      "loss: 0.008331  [  288/  408]\n",
      "Avg loss: 0.009166 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.011877  [    0/  408]\n",
      "loss: 0.011559  [   64/  408]\n",
      "loss: 0.011097  [  128/  408]\n",
      "loss: 0.008543  [  192/  408]\n",
      "loss: 0.007908  [  256/  408]\n",
      "loss: 0.010545  [  320/  408]\n",
      "loss: 0.007311  [  288/  408]\n",
      "Avg loss: 0.008151 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.010705  [    0/  408]\n",
      "loss: 0.010278  [   64/  408]\n",
      "loss: 0.009336  [  128/  408]\n",
      "loss: 0.007095  [  192/  408]\n",
      "loss: 0.006995  [  256/  408]\n",
      "loss: 0.008218  [  320/  408]\n",
      "loss: 0.005597  [  288/  408]\n",
      "Avg loss: 0.007313 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.009325  [    0/  408]\n",
      "loss: 0.008862  [   64/  408]\n",
      "loss: 0.008477  [  128/  408]\n",
      "loss: 0.006556  [  192/  408]\n",
      "loss: 0.006370  [  256/  408]\n",
      "loss: 0.007423  [  320/  408]\n",
      "loss: 0.005541  [  288/  408]\n",
      "Avg loss: 0.006520 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.008262  [    0/  408]\n",
      "loss: 0.008651  [   64/  408]\n",
      "loss: 0.007644  [  128/  408]\n",
      "loss: 0.006218  [  192/  408]\n",
      "loss: 0.006078  [  256/  408]\n",
      "loss: 0.007048  [  320/  408]\n",
      "loss: 0.005176  [  288/  408]\n",
      "Avg loss: 0.006449 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.007941  [    0/  408]\n",
      "loss: 0.008746  [   64/  408]\n",
      "loss: 0.007302  [  128/  408]\n",
      "loss: 0.005881  [  192/  408]\n",
      "loss: 0.005796  [  256/  408]\n",
      "loss: 0.006856  [  320/  408]\n",
      "loss: 0.005242  [  288/  408]\n",
      "Avg loss: 0.006380 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.007703  [    0/  408]\n",
      "loss: 0.008430  [   64/  408]\n",
      "loss: 0.007379  [  128/  408]\n",
      "loss: 0.006118  [  192/  408]\n",
      "loss: 0.005623  [  256/  408]\n",
      "loss: 0.007097  [  320/  408]\n",
      "loss: 0.005407  [  288/  408]\n",
      "Avg loss: 0.006492 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.007773  [    0/  408]\n",
      "loss: 0.008653  [   64/  408]\n",
      "loss: 0.007335  [  128/  408]\n",
      "loss: 0.006271  [  192/  408]\n",
      "loss: 0.006062  [  256/  408]\n",
      "loss: 0.007234  [  320/  408]\n",
      "loss: 0.005304  [  288/  408]\n",
      "Avg loss: 0.006641 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.007670  [    0/  408]\n",
      "loss: 0.008573  [   64/  408]\n",
      "loss: 0.007208  [  128/  408]\n",
      "loss: 0.005968  [  192/  408]\n",
      "loss: 0.005609  [  256/  408]\n",
      "loss: 0.006884  [  320/  408]\n",
      "loss: 0.005120  [  288/  408]\n",
      "Avg loss: 0.006292 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.007360  [    0/  408]\n",
      "loss: 0.008393  [   64/  408]\n",
      "loss: 0.007043  [  128/  408]\n",
      "loss: 0.005852  [  192/  408]\n",
      "loss: 0.005382  [  256/  408]\n",
      "loss: 0.007197  [  320/  408]\n",
      "loss: 0.005108  [  288/  408]\n",
      "Avg loss: 0.006305 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.007628  [    0/  408]\n",
      "loss: 0.008536  [   64/  408]\n",
      "loss: 0.007257  [  128/  408]\n",
      "loss: 0.005710  [  192/  408]\n",
      "loss: 0.005842  [  256/  408]\n",
      "loss: 0.006839  [  320/  408]\n",
      "loss: 0.005057  [  288/  408]\n",
      "Avg loss: 0.006354 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.007454  [    0/  408]\n",
      "loss: 0.008627  [   64/  408]\n",
      "loss: 0.007247  [  128/  408]\n",
      "loss: 0.006006  [  192/  408]\n",
      "loss: 0.006099  [  256/  408]\n",
      "loss: 0.007461  [  320/  408]\n",
      "loss: 0.005242  [  288/  408]\n",
      "Avg loss: 0.006452 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.007620  [    0/  408]\n",
      "loss: 0.008948  [   64/  408]\n",
      "loss: 0.007162  [  128/  408]\n",
      "loss: 0.006166  [  192/  408]\n",
      "loss: 0.006077  [  256/  408]\n",
      "loss: 0.007333  [  320/  408]\n",
      "loss: 0.005430  [  288/  408]\n",
      "Avg loss: 0.006551 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.007430  [    0/  408]\n",
      "loss: 0.008686  [   64/  408]\n",
      "loss: 0.007143  [  128/  408]\n",
      "loss: 0.005955  [  192/  408]\n",
      "loss: 0.005959  [  256/  408]\n",
      "loss: 0.006990  [  320/  408]\n",
      "loss: 0.005509  [  288/  408]\n",
      "Avg loss: 0.006411 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.007609  [    0/  408]\n",
      "loss: 0.008760  [   64/  408]\n",
      "loss: 0.006980  [  128/  408]\n",
      "loss: 0.005820  [  192/  408]\n",
      "loss: 0.005766  [  256/  408]\n",
      "loss: 0.007511  [  320/  408]\n",
      "loss: 0.005534  [  288/  408]\n",
      "Avg loss: 0.006859 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.007495  [    0/  408]\n",
      "loss: 0.008624  [   64/  408]\n",
      "loss: 0.007063  [  128/  408]\n",
      "loss: 0.006219  [  192/  408]\n",
      "loss: 0.005852  [  256/  408]\n",
      "loss: 0.007358  [  320/  408]\n",
      "loss: 0.005455  [  288/  408]\n",
      "Avg loss: 0.006340 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.007404  [    0/  408]\n",
      "loss: 0.008830  [   64/  408]\n",
      "loss: 0.007157  [  128/  408]\n",
      "loss: 0.005901  [  192/  408]\n",
      "loss: 0.005628  [  256/  408]\n",
      "loss: 0.007297  [  320/  408]\n",
      "loss: 0.005705  [  288/  408]\n",
      "Avg loss: 0.006691 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.007540  [    0/  408]\n",
      "loss: 0.008437  [   64/  408]\n",
      "loss: 0.006817  [  128/  408]\n",
      "loss: 0.006389  [  192/  408]\n",
      "loss: 0.006251  [  256/  408]\n",
      "loss: 0.007010  [  320/  408]\n",
      "loss: 0.005565  [  288/  408]\n",
      "Avg loss: 0.006804 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.007558  [    0/  408]\n",
      "loss: 0.008488  [   64/  408]\n",
      "loss: 0.006859  [  128/  408]\n",
      "loss: 0.006025  [  192/  408]\n",
      "loss: 0.005857  [  256/  408]\n",
      "loss: 0.006963  [  320/  408]\n",
      "loss: 0.005387  [  288/  408]\n",
      "Avg loss: 0.006383 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.007190  [    0/  408]\n",
      "loss: 0.008464  [   64/  408]\n",
      "loss: 0.006868  [  128/  408]\n",
      "loss: 0.005844  [  192/  408]\n",
      "loss: 0.005604  [  256/  408]\n",
      "loss: 0.006700  [  320/  408]\n",
      "loss: 0.005272  [  288/  408]\n",
      "Avg loss: 0.006145 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.006931  [    0/  408]\n",
      "loss: 0.008343  [   64/  408]\n",
      "loss: 0.006977  [  128/  408]\n",
      "loss: 0.005644  [  192/  408]\n",
      "loss: 0.005376  [  256/  408]\n",
      "loss: 0.006394  [  320/  408]\n",
      "loss: 0.005106  [  288/  408]\n",
      "Avg loss: 0.006094 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.007096  [    0/  408]\n",
      "loss: 0.008482  [   64/  408]\n",
      "loss: 0.006528  [  128/  408]\n",
      "loss: 0.005624  [  192/  408]\n",
      "loss: 0.005703  [  256/  408]\n",
      "loss: 0.006315  [  320/  408]\n",
      "loss: 0.005065  [  288/  408]\n",
      "Avg loss: 0.006167 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.006971  [    0/  408]\n",
      "loss: 0.008044  [   64/  408]\n",
      "loss: 0.006225  [  128/  408]\n",
      "loss: 0.005951  [  192/  408]\n",
      "loss: 0.005581  [  256/  408]\n",
      "loss: 0.006742  [  320/  408]\n",
      "loss: 0.005138  [  288/  408]\n",
      "Avg loss: 0.006487 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.006980  [    0/  408]\n",
      "loss: 0.007971  [   64/  408]\n",
      "loss: 0.006369  [  128/  408]\n",
      "loss: 0.005983  [  192/  408]\n",
      "loss: 0.005334  [  256/  408]\n",
      "loss: 0.006371  [  320/  408]\n",
      "loss: 0.004936  [  288/  408]\n",
      "Avg loss: 0.006045 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.006529  [    0/  408]\n",
      "loss: 0.008236  [   64/  408]\n",
      "loss: 0.006573  [  128/  408]\n",
      "loss: 0.005670  [  192/  408]\n",
      "loss: 0.005088  [  256/  408]\n",
      "loss: 0.006673  [  320/  408]\n",
      "loss: 0.005104  [  288/  408]\n",
      "Avg loss: 0.005808 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.006372  [    0/  408]\n",
      "loss: 0.007588  [   64/  408]\n",
      "loss: 0.006160  [  128/  408]\n",
      "loss: 0.005648  [  192/  408]\n",
      "loss: 0.005208  [  256/  408]\n",
      "loss: 0.006222  [  320/  408]\n",
      "loss: 0.005023  [  288/  408]\n",
      "Avg loss: 0.005740 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.006572  [    0/  408]\n",
      "loss: 0.007584  [   64/  408]\n",
      "loss: 0.006062  [  128/  408]\n",
      "loss: 0.005500  [  192/  408]\n",
      "loss: 0.005044  [  256/  408]\n",
      "loss: 0.005791  [  320/  408]\n",
      "loss: 0.004731  [  288/  408]\n",
      "Avg loss: 0.005517 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.006126  [    0/  408]\n",
      "loss: 0.007078  [   64/  408]\n",
      "loss: 0.005764  [  128/  408]\n",
      "loss: 0.005734  [  192/  408]\n",
      "loss: 0.005319  [  256/  408]\n",
      "loss: 0.005859  [  320/  408]\n",
      "loss: 0.004671  [  288/  408]\n",
      "Avg loss: 0.005437 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.006075  [    0/  408]\n",
      "loss: 0.007068  [   64/  408]\n",
      "loss: 0.005673  [  128/  408]\n",
      "loss: 0.005469  [  192/  408]\n",
      "loss: 0.005161  [  256/  408]\n",
      "loss: 0.005962  [  320/  408]\n",
      "loss: 0.005010  [  288/  408]\n",
      "Avg loss: 0.005624 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.005692  [    0/  408]\n",
      "loss: 0.006953  [   64/  408]\n",
      "loss: 0.005637  [  128/  408]\n",
      "loss: 0.005654  [  192/  408]\n",
      "loss: 0.005343  [  256/  408]\n",
      "loss: 0.005840  [  320/  408]\n",
      "loss: 0.005421  [  288/  408]\n",
      "Avg loss: 0.005249 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.005937  [    0/  408]\n",
      "loss: 0.006615  [   64/  408]\n",
      "loss: 0.005459  [  128/  408]\n",
      "loss: 0.005514  [  192/  408]\n",
      "loss: 0.004759  [  256/  408]\n",
      "loss: 0.005999  [  320/  408]\n",
      "loss: 0.005295  [  288/  408]\n",
      "Avg loss: 0.005557 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.006057  [    0/  408]\n",
      "loss: 0.006548  [   64/  408]\n",
      "loss: 0.005429  [  128/  408]\n",
      "loss: 0.005591  [  192/  408]\n",
      "loss: 0.004844  [  256/  408]\n",
      "loss: 0.006534  [  320/  408]\n",
      "loss: 0.005440  [  288/  408]\n",
      "Avg loss: 0.005611 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.006160  [    0/  408]\n",
      "loss: 0.006889  [   64/  408]\n",
      "loss: 0.006136  [  128/  408]\n",
      "loss: 0.005849  [  192/  408]\n",
      "loss: 0.004460  [  256/  408]\n",
      "loss: 0.005801  [  320/  408]\n",
      "loss: 0.004877  [  288/  408]\n",
      "Avg loss: 0.005239 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.005877  [    0/  408]\n",
      "loss: 0.006638  [   64/  408]\n",
      "loss: 0.005538  [  128/  408]\n",
      "loss: 0.005472  [  192/  408]\n",
      "loss: 0.005294  [  256/  408]\n",
      "loss: 0.006274  [  320/  408]\n",
      "loss: 0.005251  [  288/  408]\n",
      "Avg loss: 0.005615 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.006029  [    0/  408]\n",
      "loss: 0.006520  [   64/  408]\n",
      "loss: 0.005339  [  128/  408]\n",
      "loss: 0.005441  [  192/  408]\n",
      "loss: 0.004896  [  256/  408]\n",
      "loss: 0.005700  [  320/  408]\n",
      "loss: 0.005441  [  288/  408]\n",
      "Avg loss: 0.005222 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.005701  [    0/  408]\n",
      "loss: 0.006666  [   64/  408]\n",
      "loss: 0.005430  [  128/  408]\n",
      "loss: 0.005619  [  192/  408]\n",
      "loss: 0.004529  [  256/  408]\n",
      "loss: 0.005897  [  320/  408]\n",
      "loss: 0.005316  [  288/  408]\n",
      "Avg loss: 0.005199 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.005369  [    0/  408]\n",
      "loss: 0.006828  [   64/  408]\n",
      "loss: 0.005171  [  128/  408]\n",
      "loss: 0.005373  [  192/  408]\n",
      "loss: 0.004760  [  256/  408]\n",
      "loss: 0.005563  [  320/  408]\n",
      "loss: 0.005211  [  288/  408]\n",
      "Avg loss: 0.005252 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.005409  [    0/  408]\n",
      "loss: 0.006550  [   64/  408]\n",
      "loss: 0.004957  [  128/  408]\n",
      "loss: 0.005103  [  192/  408]\n",
      "loss: 0.004897  [  256/  408]\n",
      "loss: 0.005764  [  320/  408]\n",
      "loss: 0.004648  [  288/  408]\n",
      "Avg loss: 0.004970 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.005337  [    0/  408]\n",
      "loss: 0.006411  [   64/  408]\n",
      "loss: 0.005206  [  128/  408]\n",
      "loss: 0.005074  [  192/  408]\n",
      "loss: 0.004684  [  256/  408]\n",
      "loss: 0.006017  [  320/  408]\n",
      "loss: 0.005143  [  288/  408]\n",
      "Avg loss: 0.005180 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.005533  [    0/  408]\n",
      "loss: 0.006588  [   64/  408]\n",
      "loss: 0.005256  [  128/  408]\n",
      "loss: 0.005113  [  192/  408]\n",
      "loss: 0.004477  [  256/  408]\n",
      "loss: 0.005554  [  320/  408]\n",
      "loss: 0.004972  [  288/  408]\n",
      "Avg loss: 0.004926 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.005405  [    0/  408]\n",
      "loss: 0.006617  [   64/  408]\n",
      "loss: 0.005245  [  128/  408]\n",
      "loss: 0.005360  [  192/  408]\n",
      "loss: 0.004622  [  256/  408]\n",
      "loss: 0.005409  [  320/  408]\n",
      "loss: 0.004784  [  288/  408]\n",
      "Avg loss: 0.005075 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.005369  [    0/  408]\n",
      "loss: 0.006215  [   64/  408]\n",
      "loss: 0.005260  [  128/  408]\n",
      "loss: 0.005519  [  192/  408]\n",
      "loss: 0.005093  [  256/  408]\n",
      "loss: 0.005850  [  320/  408]\n",
      "loss: 0.004893  [  288/  408]\n",
      "Avg loss: 0.005155 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.005460  [    0/  408]\n",
      "loss: 0.006361  [   64/  408]\n",
      "loss: 0.004985  [  128/  408]\n",
      "loss: 0.005303  [  192/  408]\n",
      "loss: 0.004502  [  256/  408]\n",
      "loss: 0.005518  [  320/  408]\n",
      "loss: 0.004730  [  288/  408]\n",
      "Avg loss: 0.005025 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.005367  [    0/  408]\n",
      "loss: 0.006360  [   64/  408]\n",
      "loss: 0.004852  [  128/  408]\n",
      "loss: 0.005001  [  192/  408]\n",
      "loss: 0.004923  [  256/  408]\n",
      "loss: 0.005478  [  320/  408]\n",
      "loss: 0.004716  [  288/  408]\n",
      "Avg loss: 0.004944 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.005242  [    0/  408]\n",
      "loss: 0.006632  [   64/  408]\n",
      "loss: 0.004915  [  128/  408]\n",
      "loss: 0.005067  [  192/  408]\n",
      "loss: 0.004693  [  256/  408]\n",
      "loss: 0.006063  [  320/  408]\n",
      "loss: 0.004986  [  288/  408]\n",
      "Avg loss: 0.005139 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.005340  [    0/  408]\n",
      "loss: 0.006575  [   64/  408]\n",
      "loss: 0.004934  [  128/  408]\n",
      "loss: 0.005420  [  192/  408]\n",
      "loss: 0.004573  [  256/  408]\n",
      "loss: 0.005628  [  320/  408]\n",
      "loss: 0.004889  [  288/  408]\n",
      "Avg loss: 0.004944 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.005274  [    0/  408]\n",
      "loss: 0.006531  [   64/  408]\n",
      "loss: 0.004856  [  128/  408]\n",
      "loss: 0.005217  [  192/  408]\n",
      "loss: 0.004208  [  256/  408]\n",
      "loss: 0.005372  [  320/  408]\n",
      "loss: 0.004953  [  288/  408]\n",
      "Avg loss: 0.004637 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.005174  [    0/  408]\n",
      "loss: 0.006434  [   64/  408]\n",
      "loss: 0.005125  [  128/  408]\n",
      "loss: 0.004977  [  192/  408]\n",
      "loss: 0.004602  [  256/  408]\n",
      "loss: 0.005575  [  320/  408]\n",
      "loss: 0.004613  [  288/  408]\n",
      "Avg loss: 0.004934 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.005344  [    0/  408]\n",
      "loss: 0.006554  [   64/  408]\n",
      "loss: 0.005216  [  128/  408]\n",
      "loss: 0.005554  [  192/  408]\n",
      "loss: 0.004395  [  256/  408]\n",
      "loss: 0.005400  [  320/  408]\n",
      "loss: 0.004854  [  288/  408]\n",
      "Avg loss: 0.004984 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.005522  [    0/  408]\n",
      "loss: 0.006459  [   64/  408]\n",
      "loss: 0.005255  [  128/  408]\n",
      "loss: 0.005492  [  192/  408]\n",
      "loss: 0.004649  [  256/  408]\n",
      "loss: 0.005687  [  320/  408]\n",
      "loss: 0.004726  [  288/  408]\n",
      "Avg loss: 0.005133 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.005103  [    0/  408]\n",
      "loss: 0.006596  [   64/  408]\n",
      "loss: 0.005152  [  128/  408]\n",
      "loss: 0.005382  [  192/  408]\n",
      "loss: 0.004662  [  256/  408]\n",
      "loss: 0.005392  [  320/  408]\n",
      "loss: 0.004766  [  288/  408]\n",
      "Avg loss: 0.005092 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.005117  [    0/  408]\n",
      "loss: 0.006758  [   64/  408]\n",
      "loss: 0.004902  [  128/  408]\n",
      "loss: 0.005347  [  192/  408]\n",
      "loss: 0.004027  [  256/  408]\n",
      "loss: 0.004944  [  320/  408]\n",
      "loss: 0.004688  [  288/  408]\n",
      "Avg loss: 0.005065 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.005033  [    0/  408]\n",
      "loss: 0.006826  [   64/  408]\n",
      "loss: 0.004625  [  128/  408]\n",
      "loss: 0.005820  [  192/  408]\n",
      "loss: 0.004721  [  256/  408]\n",
      "loss: 0.005039  [  320/  408]\n",
      "loss: 0.004674  [  288/  408]\n",
      "Avg loss: 0.005155 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.005168  [    0/  408]\n",
      "loss: 0.006614  [   64/  408]\n",
      "loss: 0.004750  [  128/  408]\n",
      "loss: 0.005444  [  192/  408]\n",
      "loss: 0.004542  [  256/  408]\n",
      "loss: 0.005387  [  320/  408]\n",
      "loss: 0.004667  [  288/  408]\n",
      "Avg loss: 0.004986 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.005106  [    0/  408]\n",
      "loss: 0.006405  [   64/  408]\n",
      "loss: 0.004745  [  128/  408]\n",
      "loss: 0.005237  [  192/  408]\n",
      "loss: 0.004375  [  256/  408]\n",
      "loss: 0.005465  [  320/  408]\n",
      "loss: 0.004558  [  288/  408]\n",
      "Avg loss: 0.004884 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.005462  [    0/  408]\n",
      "loss: 0.006319  [   64/  408]\n",
      "loss: 0.004782  [  128/  408]\n",
      "loss: 0.005163  [  192/  408]\n",
      "loss: 0.004683  [  256/  408]\n",
      "loss: 0.004935  [  320/  408]\n",
      "loss: 0.004708  [  288/  408]\n",
      "Avg loss: 0.005505 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.005579  [    0/  408]\n",
      "loss: 0.006515  [   64/  408]\n",
      "loss: 0.004674  [  128/  408]\n",
      "loss: 0.005373  [  192/  408]\n",
      "loss: 0.004343  [  256/  408]\n",
      "loss: 0.005422  [  320/  408]\n",
      "loss: 0.005141  [  288/  408]\n",
      "Avg loss: 0.004981 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.005519  [    0/  408]\n",
      "loss: 0.006156  [   64/  408]\n",
      "loss: 0.004915  [  128/  408]\n",
      "loss: 0.005554  [  192/  408]\n",
      "loss: 0.004598  [  256/  408]\n",
      "loss: 0.006026  [  320/  408]\n",
      "loss: 0.004817  [  288/  408]\n",
      "Avg loss: 0.004888 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.005274  [    0/  408]\n",
      "loss: 0.006357  [   64/  408]\n",
      "loss: 0.004654  [  128/  408]\n",
      "loss: 0.004995  [  192/  408]\n",
      "loss: 0.004382  [  256/  408]\n",
      "loss: 0.005331  [  320/  408]\n",
      "loss: 0.005030  [  288/  408]\n",
      "Avg loss: 0.004750 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.005310  [    0/  408]\n",
      "loss: 0.006301  [   64/  408]\n",
      "loss: 0.005055  [  128/  408]\n",
      "loss: 0.005318  [  192/  408]\n",
      "loss: 0.004088  [  256/  408]\n",
      "loss: 0.005728  [  320/  408]\n",
      "loss: 0.005029  [  288/  408]\n",
      "Avg loss: 0.005284 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.005630  [    0/  408]\n",
      "loss: 0.006344  [   64/  408]\n",
      "loss: 0.004785  [  128/  408]\n",
      "loss: 0.005146  [  192/  408]\n",
      "loss: 0.004428  [  256/  408]\n",
      "loss: 0.005501  [  320/  408]\n",
      "loss: 0.004826  [  288/  408]\n",
      "Avg loss: 0.004875 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.005074  [    0/  408]\n",
      "loss: 0.005965  [   64/  408]\n",
      "loss: 0.004835  [  128/  408]\n",
      "loss: 0.005453  [  192/  408]\n",
      "loss: 0.004388  [  256/  408]\n",
      "loss: 0.005219  [  320/  408]\n",
      "loss: 0.004639  [  288/  408]\n",
      "Avg loss: 0.005076 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.005342  [    0/  408]\n",
      "loss: 0.006050  [   64/  408]\n",
      "loss: 0.004917  [  128/  408]\n",
      "loss: 0.005131  [  192/  408]\n",
      "loss: 0.003971  [  256/  408]\n",
      "loss: 0.005399  [  320/  408]\n",
      "loss: 0.004845  [  288/  408]\n",
      "Avg loss: 0.004765 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.004906  [    0/  408]\n",
      "loss: 0.006033  [   64/  408]\n",
      "loss: 0.004655  [  128/  408]\n",
      "loss: 0.004971  [  192/  408]\n",
      "loss: 0.004140  [  256/  408]\n",
      "loss: 0.005002  [  320/  408]\n",
      "loss: 0.004910  [  288/  408]\n",
      "Avg loss: 0.004958 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.005477  [    0/  408]\n",
      "loss: 0.005549  [   64/  408]\n",
      "loss: 0.004665  [  128/  408]\n",
      "loss: 0.005328  [  192/  408]\n",
      "loss: 0.003912  [  256/  408]\n",
      "loss: 0.004750  [  320/  408]\n",
      "loss: 0.004650  [  288/  408]\n",
      "Avg loss: 0.004470 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.004395  [    0/  408]\n",
      "loss: 0.005316  [   64/  408]\n",
      "loss: 0.004569  [  128/  408]\n",
      "loss: 0.005153  [  192/  408]\n",
      "loss: 0.003754  [  256/  408]\n",
      "loss: 0.004295  [  320/  408]\n",
      "loss: 0.004721  [  288/  408]\n",
      "Avg loss: 0.004131 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.003986  [    0/  408]\n",
      "loss: 0.004730  [   64/  408]\n",
      "loss: 0.003672  [  128/  408]\n",
      "loss: 0.004324  [  192/  408]\n",
      "loss: 0.003975  [  256/  408]\n",
      "loss: 0.004902  [  320/  408]\n",
      "loss: 0.004234  [  288/  408]\n",
      "Avg loss: 0.004068 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.004015  [    0/  408]\n",
      "loss: 0.004362  [   64/  408]\n",
      "loss: 0.004005  [  128/  408]\n",
      "loss: 0.004277  [  192/  408]\n",
      "loss: 0.003636  [  256/  408]\n",
      "loss: 0.003788  [  320/  408]\n",
      "loss: 0.003301  [  288/  408]\n",
      "Avg loss: 0.003520 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.003725  [    0/  408]\n",
      "loss: 0.003797  [   64/  408]\n",
      "loss: 0.003896  [  128/  408]\n",
      "loss: 0.003656  [  192/  408]\n",
      "loss: 0.003414  [  256/  408]\n",
      "loss: 0.003367  [  320/  408]\n",
      "loss: 0.003053  [  288/  408]\n",
      "Avg loss: 0.003951 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.004143  [    0/  408]\n",
      "loss: 0.003729  [   64/  408]\n",
      "loss: 0.003356  [  128/  408]\n",
      "loss: 0.003958  [  192/  408]\n",
      "loss: 0.003193  [  256/  408]\n",
      "loss: 0.003269  [  320/  408]\n",
      "loss: 0.003296  [  288/  408]\n",
      "Avg loss: 0.003709 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.003635  [    0/  408]\n",
      "loss: 0.003721  [   64/  408]\n",
      "loss: 0.003489  [  128/  408]\n",
      "loss: 0.003863  [  192/  408]\n",
      "loss: 0.003241  [  256/  408]\n",
      "loss: 0.003273  [  320/  408]\n",
      "loss: 0.003130  [  288/  408]\n",
      "Avg loss: 0.003547 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.003219  [    0/  408]\n",
      "loss: 0.003627  [   64/  408]\n",
      "loss: 0.003399  [  128/  408]\n",
      "loss: 0.003860  [  192/  408]\n",
      "loss: 0.003306  [  256/  408]\n",
      "loss: 0.003591  [  320/  408]\n",
      "loss: 0.003475  [  288/  408]\n",
      "Avg loss: 0.003323 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.003244  [    0/  408]\n",
      "loss: 0.003503  [   64/  408]\n",
      "loss: 0.003897  [  128/  408]\n",
      "loss: 0.003727  [  192/  408]\n",
      "loss: 0.002952  [  256/  408]\n",
      "loss: 0.003372  [  320/  408]\n",
      "loss: 0.002964  [  288/  408]\n",
      "Avg loss: 0.003345 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.003369  [    0/  408]\n",
      "loss: 0.003749  [   64/  408]\n",
      "loss: 0.003443  [  128/  408]\n",
      "loss: 0.003677  [  192/  408]\n",
      "loss: 0.002963  [  256/  408]\n",
      "loss: 0.003236  [  320/  408]\n",
      "loss: 0.003194  [  288/  408]\n",
      "Avg loss: 0.003346 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.003436  [    0/  408]\n",
      "loss: 0.003478  [   64/  408]\n",
      "loss: 0.003486  [  128/  408]\n",
      "loss: 0.003814  [  192/  408]\n",
      "loss: 0.003077  [  256/  408]\n",
      "loss: 0.003601  [  320/  408]\n",
      "loss: 0.003064  [  288/  408]\n",
      "Avg loss: 0.003496 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.003664  [    0/  408]\n",
      "loss: 0.003784  [   64/  408]\n",
      "loss: 0.003224  [  128/  408]\n",
      "loss: 0.003443  [  192/  408]\n",
      "loss: 0.003396  [  256/  408]\n",
      "loss: 0.003081  [  320/  408]\n",
      "loss: 0.003151  [  288/  408]\n",
      "Avg loss: 0.003766 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.003689  [    0/  408]\n",
      "loss: 0.003503  [   64/  408]\n",
      "loss: 0.003845  [  128/  408]\n",
      "loss: 0.003640  [  192/  408]\n",
      "loss: 0.003306  [  256/  408]\n",
      "loss: 0.003375  [  320/  408]\n",
      "loss: 0.003240  [  288/  408]\n",
      "Avg loss: 0.003908 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.003710  [    0/  408]\n",
      "loss: 0.003354  [   64/  408]\n",
      "loss: 0.003481  [  128/  408]\n",
      "loss: 0.003643  [  192/  408]\n",
      "loss: 0.002977  [  256/  408]\n",
      "loss: 0.003125  [  320/  408]\n",
      "loss: 0.002936  [  288/  408]\n",
      "Avg loss: 0.003263 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.003149  [    0/  408]\n",
      "loss: 0.003445  [   64/  408]\n",
      "loss: 0.003168  [  128/  408]\n",
      "loss: 0.003674  [  192/  408]\n",
      "loss: 0.002916  [  256/  408]\n",
      "loss: 0.003256  [  320/  408]\n",
      "loss: 0.002892  [  288/  408]\n",
      "Avg loss: 0.003339 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.003248  [    0/  408]\n",
      "loss: 0.003169  [   64/  408]\n",
      "loss: 0.003309  [  128/  408]\n",
      "loss: 0.003387  [  192/  408]\n",
      "loss: 0.003010  [  256/  408]\n",
      "loss: 0.003097  [  320/  408]\n",
      "loss: 0.002780  [  288/  408]\n",
      "Avg loss: 0.003163 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.003104  [    0/  408]\n",
      "loss: 0.003151  [   64/  408]\n",
      "loss: 0.003195  [  128/  408]\n",
      "loss: 0.003716  [  192/  408]\n",
      "loss: 0.003006  [  256/  408]\n",
      "loss: 0.003085  [  320/  408]\n",
      "loss: 0.003175  [  288/  408]\n",
      "Avg loss: 0.003327 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.003087  [    0/  408]\n",
      "loss: 0.003082  [   64/  408]\n",
      "loss: 0.003111  [  128/  408]\n",
      "loss: 0.003389  [  192/  408]\n",
      "loss: 0.003385  [  256/  408]\n",
      "loss: 0.002968  [  320/  408]\n",
      "loss: 0.002922  [  288/  408]\n",
      "Avg loss: 0.003192 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.003297  [    0/  408]\n",
      "loss: 0.003392  [   64/  408]\n",
      "loss: 0.002976  [  128/  408]\n",
      "loss: 0.003302  [  192/  408]\n",
      "loss: 0.002884  [  256/  408]\n",
      "loss: 0.002922  [  320/  408]\n",
      "loss: 0.003037  [  288/  408]\n",
      "Avg loss: 0.003482 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.003310  [    0/  408]\n",
      "loss: 0.003288  [   64/  408]\n",
      "loss: 0.003139  [  128/  408]\n",
      "loss: 0.003628  [  192/  408]\n",
      "loss: 0.002905  [  256/  408]\n",
      "loss: 0.002954  [  320/  408]\n",
      "loss: 0.002840  [  288/  408]\n",
      "Avg loss: 0.003122 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.003318  [    0/  408]\n",
      "loss: 0.003166  [   64/  408]\n",
      "loss: 0.003109  [  128/  408]\n",
      "loss: 0.003183  [  192/  408]\n",
      "loss: 0.002808  [  256/  408]\n",
      "loss: 0.003234  [  320/  408]\n",
      "loss: 0.002869  [  288/  408]\n",
      "Avg loss: 0.003154 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.003258  [    0/  408]\n",
      "loss: 0.003289  [   64/  408]\n",
      "loss: 0.003053  [  128/  408]\n",
      "loss: 0.003257  [  192/  408]\n",
      "loss: 0.002763  [  256/  408]\n",
      "loss: 0.002938  [  320/  408]\n",
      "loss: 0.002631  [  288/  408]\n",
      "Avg loss: 0.003055 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.002868  [    0/  408]\n",
      "loss: 0.003399  [   64/  408]\n",
      "loss: 0.003011  [  128/  408]\n",
      "loss: 0.003316  [  192/  408]\n",
      "loss: 0.002818  [  256/  408]\n",
      "loss: 0.003169  [  320/  408]\n",
      "loss: 0.003248  [  288/  408]\n",
      "Avg loss: 0.003208 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.003074  [    0/  408]\n",
      "loss: 0.003271  [   64/  408]\n",
      "loss: 0.002969  [  128/  408]\n",
      "loss: 0.003178  [  192/  408]\n",
      "loss: 0.002996  [  256/  408]\n",
      "loss: 0.002841  [  320/  408]\n",
      "loss: 0.002746  [  288/  408]\n",
      "Avg loss: 0.003328 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.003040  [    0/  408]\n",
      "loss: 0.003047  [   64/  408]\n",
      "loss: 0.002997  [  128/  408]\n",
      "loss: 0.003280  [  192/  408]\n",
      "loss: 0.002810  [  256/  408]\n",
      "loss: 0.003014  [  320/  408]\n",
      "loss: 0.002754  [  288/  408]\n",
      "Avg loss: 0.003180 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.003208  [    0/  408]\n",
      "loss: 0.003113  [   64/  408]\n",
      "loss: 0.003041  [  128/  408]\n",
      "loss: 0.003240  [  192/  408]\n",
      "loss: 0.002905  [  256/  408]\n",
      "loss: 0.003040  [  320/  408]\n",
      "loss: 0.002896  [  288/  408]\n",
      "Avg loss: 0.003174 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.002931  [    0/  408]\n",
      "loss: 0.003136  [   64/  408]\n",
      "loss: 0.003116  [  128/  408]\n",
      "loss: 0.003080  [  192/  408]\n",
      "loss: 0.002899  [  256/  408]\n",
      "loss: 0.002858  [  320/  408]\n",
      "loss: 0.002686  [  288/  408]\n",
      "Avg loss: 0.003085 \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 0.002823  [    0/  408]\n",
      "loss: 0.003126  [   64/  408]\n",
      "loss: 0.002997  [  128/  408]\n",
      "loss: 0.003373  [  192/  408]\n",
      "loss: 0.002918  [  256/  408]\n",
      "loss: 0.002889  [  320/  408]\n",
      "loss: 0.003028  [  288/  408]\n",
      "Avg loss: 0.003468 \n",
      "\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "loss: 0.003420  [    0/  408]\n",
      "loss: 0.003432  [   64/  408]\n",
      "loss: 0.003252  [  128/  408]\n",
      "loss: 0.003666  [  192/  408]\n",
      "loss: 0.002772  [  256/  408]\n",
      "loss: 0.003088  [  320/  408]\n",
      "loss: 0.002788  [  288/  408]\n",
      "Avg loss: 0.003346 \n",
      "\n",
      "Epoch 102\n",
      "-------------------------------\n",
      "loss: 0.002909  [    0/  408]\n",
      "loss: 0.003140  [   64/  408]\n",
      "loss: 0.002945  [  128/  408]\n",
      "loss: 0.003444  [  192/  408]\n",
      "loss: 0.002886  [  256/  408]\n",
      "loss: 0.002869  [  320/  408]\n",
      "loss: 0.002872  [  288/  408]\n",
      "Avg loss: 0.003155 \n",
      "\n",
      "Epoch 103\n",
      "-------------------------------\n",
      "loss: 0.003099  [    0/  408]\n",
      "loss: 0.003331  [   64/  408]\n",
      "loss: 0.003095  [  128/  408]\n",
      "loss: 0.003090  [  192/  408]\n",
      "loss: 0.002980  [  256/  408]\n",
      "loss: 0.002820  [  320/  408]\n",
      "loss: 0.002933  [  288/  408]\n",
      "Avg loss: 0.003209 \n",
      "\n",
      "Epoch 104\n",
      "-------------------------------\n",
      "loss: 0.003164  [    0/  408]\n",
      "loss: 0.003379  [   64/  408]\n",
      "loss: 0.002952  [  128/  408]\n",
      "loss: 0.003169  [  192/  408]\n",
      "loss: 0.002898  [  256/  408]\n",
      "loss: 0.002996  [  320/  408]\n",
      "loss: 0.003167  [  288/  408]\n",
      "Avg loss: 0.003118 \n",
      "\n",
      "Epoch 105\n",
      "-------------------------------\n",
      "loss: 0.003060  [    0/  408]\n",
      "loss: 0.003242  [   64/  408]\n",
      "loss: 0.003036  [  128/  408]\n",
      "loss: 0.003067  [  192/  408]\n",
      "loss: 0.002960  [  256/  408]\n",
      "loss: 0.003186  [  320/  408]\n",
      "loss: 0.002769  [  288/  408]\n",
      "Avg loss: 0.003138 \n",
      "\n",
      "Epoch 106\n",
      "-------------------------------\n",
      "loss: 0.003098  [    0/  408]\n",
      "loss: 0.003281  [   64/  408]\n",
      "loss: 0.003461  [  128/  408]\n",
      "loss: 0.003345  [  192/  408]\n",
      "loss: 0.002827  [  256/  408]\n",
      "loss: 0.003087  [  320/  408]\n",
      "loss: 0.002813  [  288/  408]\n",
      "Avg loss: 0.003131 \n",
      "\n",
      "Epoch 107\n",
      "-------------------------------\n",
      "loss: 0.002906  [    0/  408]\n",
      "loss: 0.003405  [   64/  408]\n",
      "loss: 0.003010  [  128/  408]\n",
      "loss: 0.003276  [  192/  408]\n",
      "loss: 0.003109  [  256/  408]\n",
      "loss: 0.002971  [  320/  408]\n",
      "loss: 0.002459  [  288/  408]\n",
      "Avg loss: 0.003066 \n",
      "\n",
      "Epoch 108\n",
      "-------------------------------\n",
      "loss: 0.003070  [    0/  408]\n",
      "loss: 0.003226  [   64/  408]\n",
      "loss: 0.003261  [  128/  408]\n",
      "loss: 0.003354  [  192/  408]\n",
      "loss: 0.002779  [  256/  408]\n",
      "loss: 0.002968  [  320/  408]\n",
      "loss: 0.002547  [  288/  408]\n",
      "Avg loss: 0.003011 \n",
      "\n",
      "Epoch 109\n",
      "-------------------------------\n",
      "loss: 0.002927  [    0/  408]\n",
      "loss: 0.003333  [   64/  408]\n",
      "loss: 0.002995  [  128/  408]\n",
      "loss: 0.003281  [  192/  408]\n",
      "loss: 0.002830  [  256/  408]\n",
      "loss: 0.002921  [  320/  408]\n",
      "loss: 0.003066  [  288/  408]\n",
      "Avg loss: 0.003058 \n",
      "\n",
      "Epoch 110\n",
      "-------------------------------\n",
      "loss: 0.003022  [    0/  408]\n",
      "loss: 0.003159  [   64/  408]\n",
      "loss: 0.003373  [  128/  408]\n",
      "loss: 0.003235  [  192/  408]\n",
      "loss: 0.002724  [  256/  408]\n",
      "loss: 0.002901  [  320/  408]\n",
      "loss: 0.002717  [  288/  408]\n",
      "Avg loss: 0.002970 \n",
      "\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "loss: 0.002707  [    0/  408]\n",
      "loss: 0.003374  [   64/  408]\n",
      "loss: 0.003141  [  128/  408]\n",
      "loss: 0.003235  [  192/  408]\n",
      "loss: 0.002747  [  256/  408]\n",
      "loss: 0.002981  [  320/  408]\n",
      "loss: 0.003149  [  288/  408]\n",
      "Avg loss: 0.003111 \n",
      "\n",
      "Epoch 112\n",
      "-------------------------------\n",
      "loss: 0.002987  [    0/  408]\n",
      "loss: 0.003563  [   64/  408]\n",
      "loss: 0.003588  [  128/  408]\n",
      "loss: 0.003075  [  192/  408]\n",
      "loss: 0.002900  [  256/  408]\n",
      "loss: 0.003042  [  320/  408]\n",
      "loss: 0.002549  [  288/  408]\n",
      "Avg loss: 0.003528 \n",
      "\n",
      "Epoch 113\n",
      "-------------------------------\n",
      "loss: 0.003262  [    0/  408]\n",
      "loss: 0.003088  [   64/  408]\n",
      "loss: 0.002873  [  128/  408]\n",
      "loss: 0.003170  [  192/  408]\n",
      "loss: 0.002720  [  256/  408]\n",
      "loss: 0.002713  [  320/  408]\n",
      "loss: 0.002739  [  288/  408]\n",
      "Avg loss: 0.002999 \n",
      "\n",
      "Epoch 114\n",
      "-------------------------------\n",
      "loss: 0.003013  [    0/  408]\n",
      "loss: 0.002892  [   64/  408]\n",
      "loss: 0.002934  [  128/  408]\n",
      "loss: 0.003136  [  192/  408]\n",
      "loss: 0.002786  [  256/  408]\n",
      "loss: 0.003131  [  320/  408]\n",
      "loss: 0.002721  [  288/  408]\n",
      "Avg loss: 0.002974 \n",
      "\n",
      "Epoch 115\n",
      "-------------------------------\n",
      "loss: 0.003016  [    0/  408]\n",
      "loss: 0.003124  [   64/  408]\n",
      "loss: 0.002892  [  128/  408]\n",
      "loss: 0.002971  [  192/  408]\n",
      "loss: 0.002822  [  256/  408]\n",
      "loss: 0.002694  [  320/  408]\n",
      "loss: 0.002649  [  288/  408]\n",
      "Avg loss: 0.002974 \n",
      "\n",
      "Epoch 116\n",
      "-------------------------------\n",
      "loss: 0.002768  [    0/  408]\n",
      "loss: 0.003065  [   64/  408]\n",
      "loss: 0.002870  [  128/  408]\n",
      "loss: 0.002982  [  192/  408]\n",
      "loss: 0.002607  [  256/  408]\n",
      "loss: 0.002808  [  320/  408]\n",
      "loss: 0.002691  [  288/  408]\n",
      "Avg loss: 0.003309 \n",
      "\n",
      "Epoch 117\n",
      "-------------------------------\n",
      "loss: 0.003321  [    0/  408]\n",
      "loss: 0.003325  [   64/  408]\n",
      "loss: 0.002789  [  128/  408]\n",
      "loss: 0.003395  [  192/  408]\n",
      "loss: 0.002621  [  256/  408]\n",
      "loss: 0.002865  [  320/  408]\n",
      "loss: 0.002758  [  288/  408]\n",
      "Avg loss: 0.002961 \n",
      "\n",
      "Epoch 118\n",
      "-------------------------------\n",
      "loss: 0.003095  [    0/  408]\n",
      "loss: 0.003033  [   64/  408]\n",
      "loss: 0.003014  [  128/  408]\n",
      "loss: 0.003226  [  192/  408]\n",
      "loss: 0.003115  [  256/  408]\n",
      "loss: 0.003075  [  320/  408]\n",
      "loss: 0.002577  [  288/  408]\n",
      "Avg loss: 0.003572 \n",
      "\n",
      "Epoch 119\n",
      "-------------------------------\n",
      "loss: 0.003326  [    0/  408]\n",
      "loss: 0.003362  [   64/  408]\n",
      "loss: 0.002990  [  128/  408]\n",
      "loss: 0.003446  [  192/  408]\n",
      "loss: 0.002796  [  256/  408]\n",
      "loss: 0.003525  [  320/  408]\n",
      "loss: 0.002708  [  288/  408]\n",
      "Avg loss: 0.003176 \n",
      "\n",
      "Epoch 120\n",
      "-------------------------------\n",
      "loss: 0.003154  [    0/  408]\n",
      "loss: 0.003204  [   64/  408]\n",
      "loss: 0.002882  [  128/  408]\n",
      "loss: 0.003209  [  192/  408]\n",
      "loss: 0.002801  [  256/  408]\n",
      "loss: 0.002843  [  320/  408]\n",
      "loss: 0.002725  [  288/  408]\n",
      "Avg loss: 0.003057 \n",
      "\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "loss: 0.002786  [    0/  408]\n",
      "loss: 0.003159  [   64/  408]\n",
      "loss: 0.002986  [  128/  408]\n",
      "loss: 0.003271  [  192/  408]\n",
      "loss: 0.002999  [  256/  408]\n",
      "loss: 0.002808  [  320/  408]\n",
      "loss: 0.002720  [  288/  408]\n",
      "Avg loss: 0.002905 \n",
      "\n",
      "Epoch 122\n",
      "-------------------------------\n",
      "loss: 0.002894  [    0/  408]\n",
      "loss: 0.003248  [   64/  408]\n",
      "loss: 0.002980  [  128/  408]\n",
      "loss: 0.003319  [  192/  408]\n",
      "loss: 0.002691  [  256/  408]\n",
      "loss: 0.002751  [  320/  408]\n",
      "loss: 0.002754  [  288/  408]\n",
      "Avg loss: 0.002950 \n",
      "\n",
      "Epoch 123\n",
      "-------------------------------\n",
      "loss: 0.002965  [    0/  408]\n",
      "loss: 0.003040  [   64/  408]\n",
      "loss: 0.002836  [  128/  408]\n",
      "loss: 0.003128  [  192/  408]\n",
      "loss: 0.002771  [  256/  408]\n",
      "loss: 0.002961  [  320/  408]\n",
      "loss: 0.002802  [  288/  408]\n",
      "Avg loss: 0.003031 \n",
      "\n",
      "Epoch 124\n",
      "-------------------------------\n",
      "loss: 0.002995  [    0/  408]\n",
      "loss: 0.003050  [   64/  408]\n",
      "loss: 0.003063  [  128/  408]\n",
      "loss: 0.003115  [  192/  408]\n",
      "loss: 0.002872  [  256/  408]\n",
      "loss: 0.003052  [  320/  408]\n",
      "loss: 0.002637  [  288/  408]\n",
      "Avg loss: 0.003435 \n",
      "\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "loss: 0.003192  [    0/  408]\n",
      "loss: 0.003048  [   64/  408]\n",
      "loss: 0.003135  [  128/  408]\n",
      "loss: 0.003381  [  192/  408]\n",
      "loss: 0.002902  [  256/  408]\n",
      "loss: 0.003149  [  320/  408]\n",
      "loss: 0.002963  [  288/  408]\n",
      "Avg loss: 0.003428 \n",
      "\n",
      "Epoch 126\n",
      "-------------------------------\n",
      "loss: 0.003480  [    0/  408]\n",
      "loss: 0.003155  [   64/  408]\n",
      "loss: 0.003201  [  128/  408]\n",
      "loss: 0.003462  [  192/  408]\n",
      "loss: 0.002746  [  256/  408]\n",
      "loss: 0.002585  [  320/  408]\n",
      "loss: 0.002788  [  288/  408]\n",
      "Avg loss: 0.003049 \n",
      "\n",
      "Epoch 127\n",
      "-------------------------------\n",
      "loss: 0.002781  [    0/  408]\n",
      "loss: 0.003062  [   64/  408]\n",
      "loss: 0.002714  [  128/  408]\n",
      "loss: 0.003162  [  192/  408]\n",
      "loss: 0.002778  [  256/  408]\n",
      "loss: 0.002730  [  320/  408]\n",
      "loss: 0.002610  [  288/  408]\n",
      "Avg loss: 0.003070 \n",
      "\n",
      "Epoch 128\n",
      "-------------------------------\n",
      "loss: 0.002772  [    0/  408]\n",
      "loss: 0.003251  [   64/  408]\n",
      "loss: 0.002938  [  128/  408]\n",
      "loss: 0.003209  [  192/  408]\n",
      "loss: 0.002860  [  256/  408]\n",
      "loss: 0.002946  [  320/  408]\n",
      "loss: 0.002777  [  288/  408]\n",
      "Avg loss: 0.002919 \n",
      "\n",
      "Epoch 129\n",
      "-------------------------------\n",
      "loss: 0.002869  [    0/  408]\n",
      "loss: 0.003346  [   64/  408]\n",
      "loss: 0.003169  [  128/  408]\n",
      "loss: 0.003435  [  192/  408]\n",
      "loss: 0.002656  [  256/  408]\n",
      "loss: 0.002836  [  320/  408]\n",
      "loss: 0.002658  [  288/  408]\n",
      "Avg loss: 0.002986 \n",
      "\n",
      "Epoch 130\n",
      "-------------------------------\n",
      "loss: 0.003070  [    0/  408]\n",
      "loss: 0.002950  [   64/  408]\n",
      "loss: 0.002865  [  128/  408]\n",
      "loss: 0.003235  [  192/  408]\n",
      "loss: 0.002753  [  256/  408]\n",
      "loss: 0.002778  [  320/  408]\n",
      "loss: 0.002547  [  288/  408]\n",
      "Avg loss: 0.002954 \n",
      "\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "loss: 0.002912  [    0/  408]\n",
      "loss: 0.002926  [   64/  408]\n",
      "loss: 0.002945  [  128/  408]\n",
      "loss: 0.003124  [  192/  408]\n",
      "loss: 0.002582  [  256/  408]\n",
      "loss: 0.002882  [  320/  408]\n",
      "loss: 0.002701  [  288/  408]\n",
      "Avg loss: 0.003029 \n",
      "\n",
      "Epoch 132\n",
      "-------------------------------\n",
      "loss: 0.002892  [    0/  408]\n",
      "loss: 0.003156  [   64/  408]\n",
      "loss: 0.003025  [  128/  408]\n",
      "loss: 0.003373  [  192/  408]\n",
      "loss: 0.002670  [  256/  408]\n",
      "loss: 0.002825  [  320/  408]\n",
      "loss: 0.002671  [  288/  408]\n",
      "Avg loss: 0.002941 \n",
      "\n",
      "Epoch 133\n",
      "-------------------------------\n",
      "loss: 0.002872  [    0/  408]\n",
      "loss: 0.003208  [   64/  408]\n",
      "loss: 0.002816  [  128/  408]\n",
      "loss: 0.003034  [  192/  408]\n",
      "loss: 0.002691  [  256/  408]\n",
      "loss: 0.002812  [  320/  408]\n",
      "loss: 0.002617  [  288/  408]\n",
      "Avg loss: 0.003294 \n",
      "\n",
      "Epoch 134\n",
      "-------------------------------\n",
      "loss: 0.003249  [    0/  408]\n",
      "loss: 0.003163  [   64/  408]\n",
      "loss: 0.003009  [  128/  408]\n",
      "loss: 0.003428  [  192/  408]\n",
      "loss: 0.002805  [  256/  408]\n",
      "loss: 0.002754  [  320/  408]\n",
      "loss: 0.002791  [  288/  408]\n",
      "Avg loss: 0.003110 \n",
      "\n",
      "Epoch 135\n",
      "-------------------------------\n",
      "loss: 0.003011  [    0/  408]\n",
      "loss: 0.003216  [   64/  408]\n",
      "loss: 0.002928  [  128/  408]\n",
      "loss: 0.003384  [  192/  408]\n",
      "loss: 0.002846  [  256/  408]\n",
      "loss: 0.002755  [  320/  408]\n",
      "loss: 0.002540  [  288/  408]\n",
      "Avg loss: 0.002993 \n",
      "\n",
      "Epoch 136\n",
      "-------------------------------\n",
      "loss: 0.003044  [    0/  408]\n",
      "loss: 0.003234  [   64/  408]\n",
      "loss: 0.002845  [  128/  408]\n",
      "loss: 0.003006  [  192/  408]\n",
      "loss: 0.002628  [  256/  408]\n",
      "loss: 0.003074  [  320/  408]\n",
      "loss: 0.002647  [  288/  408]\n",
      "Avg loss: 0.003201 \n",
      "\n",
      "Epoch 137\n",
      "-------------------------------\n",
      "loss: 0.003223  [    0/  408]\n",
      "loss: 0.003325  [   64/  408]\n",
      "loss: 0.003127  [  128/  408]\n",
      "loss: 0.003088  [  192/  408]\n",
      "loss: 0.002628  [  256/  408]\n",
      "loss: 0.002836  [  320/  408]\n",
      "loss: 0.002477  [  288/  408]\n",
      "Avg loss: 0.003027 \n",
      "\n",
      "Epoch 138\n",
      "-------------------------------\n",
      "loss: 0.002782  [    0/  408]\n",
      "loss: 0.003066  [   64/  408]\n",
      "loss: 0.003113  [  128/  408]\n",
      "loss: 0.003145  [  192/  408]\n",
      "loss: 0.002902  [  256/  408]\n",
      "loss: 0.002622  [  320/  408]\n",
      "loss: 0.002819  [  288/  408]\n",
      "Avg loss: 0.002893 \n",
      "\n",
      "Epoch 139\n",
      "-------------------------------\n",
      "loss: 0.002987  [    0/  408]\n",
      "loss: 0.003012  [   64/  408]\n",
      "loss: 0.003155  [  128/  408]\n",
      "loss: 0.003069  [  192/  408]\n",
      "loss: 0.002930  [  256/  408]\n",
      "loss: 0.002968  [  320/  408]\n",
      "loss: 0.002589  [  288/  408]\n",
      "Avg loss: 0.002996 \n",
      "\n",
      "Epoch 140\n",
      "-------------------------------\n",
      "loss: 0.002931  [    0/  408]\n",
      "loss: 0.003059  [   64/  408]\n",
      "loss: 0.003191  [  128/  408]\n",
      "loss: 0.003232  [  192/  408]\n",
      "loss: 0.002736  [  256/  408]\n",
      "loss: 0.002847  [  320/  408]\n",
      "loss: 0.002556  [  288/  408]\n",
      "Avg loss: 0.003287 \n",
      "\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "loss: 0.003015  [    0/  408]\n",
      "loss: 0.003210  [   64/  408]\n",
      "loss: 0.002847  [  128/  408]\n",
      "loss: 0.002993  [  192/  408]\n",
      "loss: 0.002773  [  256/  408]\n",
      "loss: 0.002833  [  320/  408]\n",
      "loss: 0.002671  [  288/  408]\n",
      "Avg loss: 0.003105 \n",
      "\n",
      "Epoch 142\n",
      "-------------------------------\n",
      "loss: 0.003024  [    0/  408]\n",
      "loss: 0.002886  [   64/  408]\n",
      "loss: 0.002932  [  128/  408]\n",
      "loss: 0.003135  [  192/  408]\n",
      "loss: 0.002745  [  256/  408]\n",
      "loss: 0.002741  [  320/  408]\n",
      "loss: 0.002635  [  288/  408]\n",
      "Avg loss: 0.003076 \n",
      "\n",
      "Epoch 143\n",
      "-------------------------------\n",
      "loss: 0.002819  [    0/  408]\n",
      "loss: 0.002913  [   64/  408]\n",
      "loss: 0.002935  [  128/  408]\n",
      "loss: 0.003365  [  192/  408]\n",
      "loss: 0.002911  [  256/  408]\n",
      "loss: 0.002768  [  320/  408]\n",
      "loss: 0.003131  [  288/  408]\n",
      "Avg loss: 0.003163 \n",
      "\n",
      "Epoch 144\n",
      "-------------------------------\n",
      "loss: 0.002904  [    0/  408]\n",
      "loss: 0.003324  [   64/  408]\n",
      "loss: 0.003309  [  128/  408]\n",
      "loss: 0.003555  [  192/  408]\n",
      "loss: 0.002856  [  256/  408]\n",
      "loss: 0.002997  [  320/  408]\n",
      "loss: 0.002905  [  288/  408]\n",
      "Avg loss: 0.003218 \n",
      "\n",
      "Epoch 145\n",
      "-------------------------------\n",
      "loss: 0.002950  [    0/  408]\n",
      "loss: 0.003137  [   64/  408]\n",
      "loss: 0.003179  [  128/  408]\n",
      "loss: 0.003224  [  192/  408]\n",
      "loss: 0.002823  [  256/  408]\n",
      "loss: 0.002788  [  320/  408]\n",
      "loss: 0.002747  [  288/  408]\n",
      "Avg loss: 0.002996 \n",
      "\n",
      "Epoch 146\n",
      "-------------------------------\n",
      "loss: 0.002930  [    0/  408]\n",
      "loss: 0.003123  [   64/  408]\n",
      "loss: 0.002861  [  128/  408]\n",
      "loss: 0.003185  [  192/  408]\n",
      "loss: 0.002748  [  256/  408]\n",
      "loss: 0.002704  [  320/  408]\n",
      "loss: 0.002624  [  288/  408]\n",
      "Avg loss: 0.002822 \n",
      "\n",
      "Epoch 147\n",
      "-------------------------------\n",
      "loss: 0.002837  [    0/  408]\n",
      "loss: 0.002961  [   64/  408]\n",
      "loss: 0.002812  [  128/  408]\n",
      "loss: 0.003002  [  192/  408]\n",
      "loss: 0.002869  [  256/  408]\n",
      "loss: 0.002788  [  320/  408]\n",
      "loss: 0.002751  [  288/  408]\n",
      "Avg loss: 0.003095 \n",
      "\n",
      "Epoch 148\n",
      "-------------------------------\n",
      "loss: 0.002989  [    0/  408]\n",
      "loss: 0.003099  [   64/  408]\n",
      "loss: 0.002930  [  128/  408]\n",
      "loss: 0.003197  [  192/  408]\n",
      "loss: 0.002989  [  256/  408]\n",
      "loss: 0.002829  [  320/  408]\n",
      "loss: 0.002548  [  288/  408]\n",
      "Avg loss: 0.003017 \n",
      "\n",
      "Epoch 149\n",
      "-------------------------------\n",
      "loss: 0.003155  [    0/  408]\n",
      "loss: 0.002938  [   64/  408]\n",
      "loss: 0.002840  [  128/  408]\n",
      "loss: 0.003133  [  192/  408]\n",
      "loss: 0.002871  [  256/  408]\n",
      "loss: 0.002954  [  320/  408]\n",
      "loss: 0.002631  [  288/  408]\n",
      "Avg loss: 0.002990 \n",
      "\n",
      "Epoch 150\n",
      "-------------------------------\n",
      "loss: 0.002861  [    0/  408]\n",
      "loss: 0.003049  [   64/  408]\n",
      "loss: 0.002787  [  128/  408]\n",
      "loss: 0.003401  [  192/  408]\n",
      "loss: 0.002788  [  256/  408]\n",
      "loss: 0.002662  [  320/  408]\n",
      "loss: 0.002970  [  288/  408]\n",
      "Avg loss: 0.003062 \n",
      "\n",
      "Epoch 151\n",
      "-------------------------------\n",
      "loss: 0.002843  [    0/  408]\n",
      "loss: 0.003011  [   64/  408]\n",
      "loss: 0.003272  [  128/  408]\n",
      "loss: 0.003291  [  192/  408]\n",
      "loss: 0.002681  [  256/  408]\n",
      "loss: 0.003052  [  320/  408]\n",
      "loss: 0.002568  [  288/  408]\n",
      "Avg loss: 0.003042 \n",
      "\n",
      "Epoch 152\n",
      "-------------------------------\n",
      "loss: 0.003057  [    0/  408]\n",
      "loss: 0.003143  [   64/  408]\n",
      "loss: 0.003016  [  128/  408]\n",
      "loss: 0.003091  [  192/  408]\n",
      "loss: 0.002736  [  256/  408]\n",
      "loss: 0.002753  [  320/  408]\n",
      "loss: 0.002485  [  288/  408]\n",
      "Avg loss: 0.002984 \n",
      "\n",
      "Epoch 153\n",
      "-------------------------------\n",
      "loss: 0.002862  [    0/  408]\n",
      "loss: 0.003119  [   64/  408]\n",
      "loss: 0.002979  [  128/  408]\n",
      "loss: 0.003392  [  192/  408]\n",
      "loss: 0.002833  [  256/  408]\n",
      "loss: 0.002945  [  320/  408]\n",
      "loss: 0.002770  [  288/  408]\n",
      "Avg loss: 0.002848 \n",
      "\n",
      "Epoch 154\n",
      "-------------------------------\n",
      "loss: 0.002681  [    0/  408]\n",
      "loss: 0.003102  [   64/  408]\n",
      "loss: 0.003187  [  128/  408]\n",
      "loss: 0.003207  [  192/  408]\n",
      "loss: 0.002742  [  256/  408]\n",
      "loss: 0.002642  [  320/  408]\n",
      "loss: 0.002968  [  288/  408]\n",
      "Avg loss: 0.002946 \n",
      "\n",
      "Epoch 155\n",
      "-------------------------------\n",
      "loss: 0.002979  [    0/  408]\n",
      "loss: 0.003105  [   64/  408]\n",
      "loss: 0.002897  [  128/  408]\n",
      "loss: 0.003014  [  192/  408]\n",
      "loss: 0.002723  [  256/  408]\n",
      "loss: 0.003008  [  320/  408]\n",
      "loss: 0.002666  [  288/  408]\n",
      "Avg loss: 0.002970 \n",
      "\n",
      "Epoch 156\n",
      "-------------------------------\n",
      "loss: 0.003132  [    0/  408]\n",
      "loss: 0.003019  [   64/  408]\n",
      "loss: 0.002777  [  128/  408]\n",
      "loss: 0.002969  [  192/  408]\n",
      "loss: 0.002695  [  256/  408]\n",
      "loss: 0.002839  [  320/  408]\n",
      "loss: 0.002643  [  288/  408]\n",
      "Avg loss: 0.003085 \n",
      "\n",
      "Epoch 157\n",
      "-------------------------------\n",
      "loss: 0.003013  [    0/  408]\n",
      "loss: 0.003266  [   64/  408]\n",
      "loss: 0.002782  [  128/  408]\n",
      "loss: 0.002981  [  192/  408]\n",
      "loss: 0.002778  [  256/  408]\n",
      "loss: 0.002747  [  320/  408]\n",
      "loss: 0.002591  [  288/  408]\n",
      "Avg loss: 0.002863 \n",
      "\n",
      "Epoch 158\n",
      "-------------------------------\n",
      "loss: 0.002799  [    0/  408]\n",
      "loss: 0.003085  [   64/  408]\n",
      "loss: 0.003040  [  128/  408]\n",
      "loss: 0.003001  [  192/  408]\n",
      "loss: 0.002731  [  256/  408]\n",
      "loss: 0.002845  [  320/  408]\n",
      "loss: 0.002590  [  288/  408]\n",
      "Avg loss: 0.002909 \n",
      "\n",
      "Epoch 159\n",
      "-------------------------------\n",
      "loss: 0.002844  [    0/  408]\n",
      "loss: 0.002987  [   64/  408]\n",
      "loss: 0.002921  [  128/  408]\n",
      "loss: 0.003049  [  192/  408]\n",
      "loss: 0.002789  [  256/  408]\n",
      "loss: 0.002535  [  320/  408]\n",
      "loss: 0.002521  [  288/  408]\n",
      "Avg loss: 0.002890 \n",
      "\n",
      "Epoch 160\n",
      "-------------------------------\n",
      "loss: 0.002832  [    0/  408]\n",
      "loss: 0.002887  [   64/  408]\n",
      "loss: 0.002711  [  128/  408]\n",
      "loss: 0.002948  [  192/  408]\n",
      "loss: 0.002549  [  256/  408]\n",
      "loss: 0.002577  [  320/  408]\n",
      "loss: 0.002654  [  288/  408]\n",
      "Avg loss: 0.003047 \n",
      "\n",
      "Epoch 161\n",
      "-------------------------------\n",
      "loss: 0.002857  [    0/  408]\n",
      "loss: 0.003270  [   64/  408]\n",
      "loss: 0.003140  [  128/  408]\n",
      "loss: 0.002936  [  192/  408]\n",
      "loss: 0.002905  [  256/  408]\n",
      "loss: 0.002727  [  320/  408]\n",
      "loss: 0.002552  [  288/  408]\n",
      "Avg loss: 0.003139 \n",
      "\n",
      "Epoch 162\n",
      "-------------------------------\n",
      "loss: 0.003257  [    0/  408]\n",
      "loss: 0.003018  [   64/  408]\n",
      "loss: 0.002993  [  128/  408]\n",
      "loss: 0.003231  [  192/  408]\n",
      "loss: 0.002542  [  256/  408]\n",
      "loss: 0.002697  [  320/  408]\n",
      "loss: 0.002564  [  288/  408]\n",
      "Avg loss: 0.002822 \n",
      "\n",
      "Epoch 163\n",
      "-------------------------------\n",
      "loss: 0.002995  [    0/  408]\n",
      "loss: 0.002811  [   64/  408]\n",
      "loss: 0.002692  [  128/  408]\n",
      "loss: 0.002939  [  192/  408]\n",
      "loss: 0.002663  [  256/  408]\n",
      "loss: 0.002729  [  320/  408]\n",
      "loss: 0.002538  [  288/  408]\n",
      "Avg loss: 0.003070 \n",
      "\n",
      "Epoch 164\n",
      "-------------------------------\n",
      "loss: 0.003016  [    0/  408]\n",
      "loss: 0.002817  [   64/  408]\n",
      "loss: 0.002864  [  128/  408]\n",
      "loss: 0.003197  [  192/  408]\n",
      "loss: 0.002968  [  256/  408]\n",
      "loss: 0.002775  [  320/  408]\n",
      "loss: 0.002522  [  288/  408]\n",
      "Avg loss: 0.003136 \n",
      "\n",
      "Epoch 165\n",
      "-------------------------------\n",
      "loss: 0.003280  [    0/  408]\n",
      "loss: 0.003174  [   64/  408]\n",
      "loss: 0.003043  [  128/  408]\n",
      "loss: 0.003163  [  192/  408]\n",
      "loss: 0.002683  [  256/  408]\n",
      "loss: 0.002719  [  320/  408]\n",
      "loss: 0.002645  [  288/  408]\n",
      "Avg loss: 0.002901 \n",
      "\n",
      "Epoch 166\n",
      "-------------------------------\n",
      "loss: 0.002934  [    0/  408]\n",
      "loss: 0.002930  [   64/  408]\n",
      "loss: 0.002801  [  128/  408]\n",
      "loss: 0.003115  [  192/  408]\n",
      "loss: 0.002728  [  256/  408]\n",
      "loss: 0.002752  [  320/  408]\n",
      "loss: 0.002823  [  288/  408]\n",
      "Avg loss: 0.002970 \n",
      "\n",
      "Epoch 167\n",
      "-------------------------------\n",
      "loss: 0.002752  [    0/  408]\n",
      "loss: 0.002921  [   64/  408]\n",
      "loss: 0.002825  [  128/  408]\n",
      "loss: 0.003299  [  192/  408]\n",
      "loss: 0.002803  [  256/  408]\n",
      "loss: 0.002926  [  320/  408]\n",
      "loss: 0.002705  [  288/  408]\n",
      "Avg loss: 0.002982 \n",
      "\n",
      "Epoch 168\n",
      "-------------------------------\n",
      "loss: 0.002841  [    0/  408]\n",
      "loss: 0.003114  [   64/  408]\n",
      "loss: 0.002912  [  128/  408]\n",
      "loss: 0.003242  [  192/  408]\n",
      "loss: 0.002641  [  256/  408]\n",
      "loss: 0.002816  [  320/  408]\n",
      "loss: 0.002712  [  288/  408]\n",
      "Avg loss: 0.002826 \n",
      "\n",
      "Epoch 169\n",
      "-------------------------------\n",
      "loss: 0.002723  [    0/  408]\n",
      "loss: 0.002921  [   64/  408]\n",
      "loss: 0.003012  [  128/  408]\n",
      "loss: 0.003156  [  192/  408]\n",
      "loss: 0.002761  [  256/  408]\n",
      "loss: 0.002742  [  320/  408]\n",
      "loss: 0.002585  [  288/  408]\n",
      "Avg loss: 0.003104 \n",
      "\n",
      "Epoch 170\n",
      "-------------------------------\n",
      "loss: 0.003035  [    0/  408]\n",
      "loss: 0.002972  [   64/  408]\n",
      "loss: 0.002832  [  128/  408]\n",
      "loss: 0.003128  [  192/  408]\n",
      "loss: 0.002704  [  256/  408]\n",
      "loss: 0.002589  [  320/  408]\n",
      "loss: 0.002727  [  288/  408]\n",
      "Avg loss: 0.002918 \n",
      "\n",
      "Epoch 171\n",
      "-------------------------------\n",
      "loss: 0.002817  [    0/  408]\n",
      "loss: 0.002909  [   64/  408]\n",
      "loss: 0.002641  [  128/  408]\n",
      "loss: 0.003084  [  192/  408]\n",
      "loss: 0.002638  [  256/  408]\n",
      "loss: 0.002757  [  320/  408]\n",
      "loss: 0.002458  [  288/  408]\n",
      "Avg loss: 0.002855 \n",
      "\n",
      "Epoch 172\n",
      "-------------------------------\n",
      "loss: 0.002755  [    0/  408]\n",
      "loss: 0.002963  [   64/  408]\n",
      "loss: 0.002833  [  128/  408]\n",
      "loss: 0.002905  [  192/  408]\n",
      "loss: 0.002702  [  256/  408]\n",
      "loss: 0.002790  [  320/  408]\n",
      "loss: 0.002672  [  288/  408]\n",
      "Avg loss: 0.002988 \n",
      "\n",
      "Epoch 173\n",
      "-------------------------------\n",
      "loss: 0.002846  [    0/  408]\n",
      "loss: 0.003049  [   64/  408]\n",
      "loss: 0.002831  [  128/  408]\n",
      "loss: 0.003184  [  192/  408]\n",
      "loss: 0.002643  [  256/  408]\n",
      "loss: 0.002813  [  320/  408]\n",
      "loss: 0.002877  [  288/  408]\n",
      "Avg loss: 0.002987 \n",
      "\n",
      "Epoch 174\n",
      "-------------------------------\n",
      "loss: 0.002984  [    0/  408]\n",
      "loss: 0.002983  [   64/  408]\n",
      "loss: 0.002913  [  128/  408]\n",
      "loss: 0.002967  [  192/  408]\n",
      "loss: 0.002986  [  256/  408]\n",
      "loss: 0.003182  [  320/  408]\n",
      "loss: 0.002794  [  288/  408]\n",
      "Avg loss: 0.003103 \n",
      "\n",
      "Epoch 175\n",
      "-------------------------------\n",
      "loss: 0.003098  [    0/  408]\n",
      "loss: 0.003203  [   64/  408]\n",
      "loss: 0.003157  [  128/  408]\n",
      "loss: 0.003122  [  192/  408]\n",
      "loss: 0.002823  [  256/  408]\n",
      "loss: 0.003244  [  320/  408]\n",
      "loss: 0.002605  [  288/  408]\n",
      "Avg loss: 0.002977 \n",
      "\n",
      "Epoch 176\n",
      "-------------------------------\n",
      "loss: 0.003133  [    0/  408]\n",
      "loss: 0.003191  [   64/  408]\n",
      "loss: 0.002850  [  128/  408]\n",
      "loss: 0.002947  [  192/  408]\n",
      "loss: 0.002786  [  256/  408]\n",
      "loss: 0.002630  [  320/  408]\n",
      "loss: 0.002499  [  288/  408]\n",
      "Avg loss: 0.002795 \n",
      "\n",
      "Epoch 177\n",
      "-------------------------------\n",
      "loss: 0.002779  [    0/  408]\n",
      "loss: 0.002930  [   64/  408]\n",
      "loss: 0.002828  [  128/  408]\n",
      "loss: 0.003233  [  192/  408]\n",
      "loss: 0.002910  [  256/  408]\n",
      "loss: 0.002763  [  320/  408]\n",
      "loss: 0.002626  [  288/  408]\n",
      "Avg loss: 0.002828 \n",
      "\n",
      "Epoch 178\n",
      "-------------------------------\n",
      "loss: 0.002811  [    0/  408]\n",
      "loss: 0.002937  [   64/  408]\n",
      "loss: 0.002833  [  128/  408]\n",
      "loss: 0.003080  [  192/  408]\n",
      "loss: 0.003073  [  256/  408]\n",
      "loss: 0.002796  [  320/  408]\n",
      "loss: 0.002502  [  288/  408]\n",
      "Avg loss: 0.002864 \n",
      "\n",
      "Epoch 179\n",
      "-------------------------------\n",
      "loss: 0.002750  [    0/  408]\n",
      "loss: 0.003044  [   64/  408]\n",
      "loss: 0.002694  [  128/  408]\n",
      "loss: 0.002929  [  192/  408]\n",
      "loss: 0.002692  [  256/  408]\n",
      "loss: 0.002801  [  320/  408]\n",
      "loss: 0.002511  [  288/  408]\n",
      "Avg loss: 0.002797 \n",
      "\n",
      "Epoch 180\n",
      "-------------------------------\n",
      "loss: 0.002826  [    0/  408]\n",
      "loss: 0.003121  [   64/  408]\n",
      "loss: 0.002774  [  128/  408]\n",
      "loss: 0.003070  [  192/  408]\n",
      "loss: 0.002899  [  256/  408]\n",
      "loss: 0.002819  [  320/  408]\n",
      "loss: 0.002650  [  288/  408]\n",
      "Avg loss: 0.003124 \n",
      "\n",
      "Epoch 181\n",
      "-------------------------------\n",
      "loss: 0.003407  [    0/  408]\n",
      "loss: 0.003245  [   64/  408]\n",
      "loss: 0.002799  [  128/  408]\n",
      "loss: 0.003263  [  192/  408]\n",
      "loss: 0.002888  [  256/  408]\n",
      "loss: 0.002843  [  320/  408]\n",
      "loss: 0.002730  [  288/  408]\n",
      "Avg loss: 0.003065 \n",
      "\n",
      "Epoch 182\n",
      "-------------------------------\n",
      "loss: 0.003144  [    0/  408]\n",
      "loss: 0.003043  [   64/  408]\n",
      "loss: 0.002723  [  128/  408]\n",
      "loss: 0.003068  [  192/  408]\n",
      "loss: 0.002703  [  256/  408]\n",
      "loss: 0.002923  [  320/  408]\n",
      "loss: 0.002649  [  288/  408]\n",
      "Avg loss: 0.002949 \n",
      "\n",
      "Epoch 183\n",
      "-------------------------------\n",
      "loss: 0.002900  [    0/  408]\n",
      "loss: 0.003080  [   64/  408]\n",
      "loss: 0.002841  [  128/  408]\n",
      "loss: 0.003005  [  192/  408]\n",
      "loss: 0.002731  [  256/  408]\n",
      "loss: 0.002991  [  320/  408]\n",
      "loss: 0.002504  [  288/  408]\n",
      "Avg loss: 0.002872 \n",
      "\n",
      "Epoch 184\n",
      "-------------------------------\n",
      "loss: 0.002703  [    0/  408]\n",
      "loss: 0.003298  [   64/  408]\n",
      "loss: 0.002792  [  128/  408]\n",
      "loss: 0.003252  [  192/  408]\n",
      "loss: 0.002979  [  256/  408]\n",
      "loss: 0.002754  [  320/  408]\n",
      "loss: 0.002807  [  288/  408]\n",
      "Avg loss: 0.002819 \n",
      "\n",
      "Epoch 185\n",
      "-------------------------------\n",
      "loss: 0.002849  [    0/  408]\n",
      "loss: 0.003065  [   64/  408]\n",
      "loss: 0.002986  [  128/  408]\n",
      "loss: 0.003200  [  192/  408]\n",
      "loss: 0.002914  [  256/  408]\n",
      "loss: 0.002840  [  320/  408]\n",
      "loss: 0.002634  [  288/  408]\n",
      "Avg loss: 0.003044 \n",
      "\n",
      "Epoch 186\n",
      "-------------------------------\n",
      "loss: 0.003155  [    0/  408]\n",
      "loss: 0.003143  [   64/  408]\n",
      "loss: 0.003148  [  128/  408]\n",
      "loss: 0.003431  [  192/  408]\n",
      "loss: 0.002738  [  256/  408]\n",
      "loss: 0.003229  [  320/  408]\n",
      "loss: 0.002647  [  288/  408]\n",
      "Avg loss: 0.003216 \n",
      "\n",
      "Epoch 187\n",
      "-------------------------------\n",
      "loss: 0.003283  [    0/  408]\n",
      "loss: 0.003060  [   64/  408]\n",
      "loss: 0.002887  [  128/  408]\n",
      "loss: 0.003489  [  192/  408]\n",
      "loss: 0.002704  [  256/  408]\n",
      "loss: 0.002931  [  320/  408]\n",
      "loss: 0.002822  [  288/  408]\n",
      "Avg loss: 0.002950 \n",
      "\n",
      "Epoch 188\n",
      "-------------------------------\n",
      "loss: 0.002936  [    0/  408]\n",
      "loss: 0.002964  [   64/  408]\n",
      "loss: 0.002945  [  128/  408]\n",
      "loss: 0.003116  [  192/  408]\n",
      "loss: 0.002696  [  256/  408]\n",
      "loss: 0.002627  [  320/  408]\n",
      "loss: 0.002518  [  288/  408]\n",
      "Avg loss: 0.002881 \n",
      "\n",
      "Epoch 189\n",
      "-------------------------------\n",
      "loss: 0.002850  [    0/  408]\n",
      "loss: 0.003313  [   64/  408]\n",
      "loss: 0.002949  [  128/  408]\n",
      "loss: 0.003252  [  192/  408]\n",
      "loss: 0.002779  [  256/  408]\n",
      "loss: 0.002680  [  320/  408]\n",
      "loss: 0.002708  [  288/  408]\n",
      "Avg loss: 0.002876 \n",
      "\n",
      "Epoch 190\n",
      "-------------------------------\n",
      "loss: 0.002725  [    0/  408]\n",
      "loss: 0.003200  [   64/  408]\n",
      "loss: 0.003023  [  128/  408]\n",
      "loss: 0.003073  [  192/  408]\n",
      "loss: 0.002700  [  256/  408]\n",
      "loss: 0.002677  [  320/  408]\n",
      "loss: 0.002691  [  288/  408]\n",
      "Avg loss: 0.002974 \n",
      "\n",
      "Epoch 191\n",
      "-------------------------------\n",
      "loss: 0.002917  [    0/  408]\n",
      "loss: 0.002989  [   64/  408]\n",
      "loss: 0.002917  [  128/  408]\n",
      "loss: 0.003056  [  192/  408]\n",
      "loss: 0.002854  [  256/  408]\n",
      "loss: 0.002741  [  320/  408]\n",
      "loss: 0.002652  [  288/  408]\n",
      "Avg loss: 0.002972 \n",
      "\n",
      "Epoch 192\n",
      "-------------------------------\n",
      "loss: 0.002824  [    0/  408]\n",
      "loss: 0.003149  [   64/  408]\n",
      "loss: 0.002763  [  128/  408]\n",
      "loss: 0.003140  [  192/  408]\n",
      "loss: 0.003146  [  256/  408]\n",
      "loss: 0.002639  [  320/  408]\n",
      "loss: 0.002828  [  288/  408]\n",
      "Avg loss: 0.003055 \n",
      "\n",
      "Epoch 193\n",
      "-------------------------------\n",
      "loss: 0.002893  [    0/  408]\n",
      "loss: 0.003302  [   64/  408]\n",
      "loss: 0.003096  [  128/  408]\n",
      "loss: 0.003114  [  192/  408]\n",
      "loss: 0.002825  [  256/  408]\n",
      "loss: 0.002924  [  320/  408]\n",
      "loss: 0.002710  [  288/  408]\n",
      "Avg loss: 0.003073 \n",
      "\n",
      "Epoch 194\n",
      "-------------------------------\n",
      "loss: 0.003135  [    0/  408]\n",
      "loss: 0.003038  [   64/  408]\n",
      "loss: 0.003039  [  128/  408]\n",
      "loss: 0.003235  [  192/  408]\n",
      "loss: 0.002787  [  256/  408]\n",
      "loss: 0.002747  [  320/  408]\n",
      "loss: 0.002809  [  288/  408]\n",
      "Avg loss: 0.002791 \n",
      "\n",
      "Epoch 195\n",
      "-------------------------------\n",
      "loss: 0.003021  [    0/  408]\n",
      "loss: 0.003374  [   64/  408]\n",
      "loss: 0.003035  [  128/  408]\n",
      "loss: 0.003118  [  192/  408]\n",
      "loss: 0.003053  [  256/  408]\n",
      "loss: 0.002649  [  320/  408]\n",
      "loss: 0.002840  [  288/  408]\n",
      "Avg loss: 0.002888 \n",
      "\n",
      "Epoch 196\n",
      "-------------------------------\n",
      "loss: 0.002890  [    0/  408]\n",
      "loss: 0.003260  [   64/  408]\n",
      "loss: 0.002721  [  128/  408]\n",
      "loss: 0.003152  [  192/  408]\n",
      "loss: 0.002572  [  256/  408]\n",
      "loss: 0.002728  [  320/  408]\n",
      "loss: 0.002585  [  288/  408]\n",
      "Avg loss: 0.003004 \n",
      "\n",
      "Epoch 197\n",
      "-------------------------------\n",
      "loss: 0.002891  [    0/  408]\n",
      "loss: 0.003136  [   64/  408]\n",
      "loss: 0.003131  [  128/  408]\n",
      "loss: 0.003304  [  192/  408]\n",
      "loss: 0.002796  [  256/  408]\n",
      "loss: 0.002840  [  320/  408]\n",
      "loss: 0.002678  [  288/  408]\n",
      "Avg loss: 0.002880 \n",
      "\n",
      "Epoch 198\n",
      "-------------------------------\n",
      "loss: 0.002753  [    0/  408]\n",
      "loss: 0.003168  [   64/  408]\n",
      "loss: 0.002833  [  128/  408]\n",
      "loss: 0.003126  [  192/  408]\n",
      "loss: 0.002804  [  256/  408]\n",
      "loss: 0.002818  [  320/  408]\n",
      "loss: 0.002935  [  288/  408]\n",
      "Avg loss: 0.002990 \n",
      "\n",
      "Epoch 199\n",
      "-------------------------------\n",
      "loss: 0.002802  [    0/  408]\n",
      "loss: 0.003003  [   64/  408]\n",
      "loss: 0.003151  [  128/  408]\n",
      "loss: 0.002993  [  192/  408]\n",
      "loss: 0.002728  [  256/  408]\n",
      "loss: 0.002782  [  320/  408]\n",
      "loss: 0.002679  [  288/  408]\n",
      "Avg loss: 0.003187 \n",
      "\n",
      "Epoch 200\n",
      "-------------------------------\n",
      "loss: 0.003091  [    0/  408]\n",
      "loss: 0.003055  [   64/  408]\n",
      "loss: 0.003006  [  128/  408]\n",
      "loss: 0.003001  [  192/  408]\n",
      "loss: 0.002535  [  256/  408]\n",
      "loss: 0.002628  [  320/  408]\n",
      "loss: 0.002494  [  288/  408]\n",
      "Avg loss: 0.002910 \n",
      "\n",
      "Done!\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run training\n",
    "epochs = 200\n",
    "loss_plot = []\n",
    "recon_plot = []\n",
    "kld_plot = []\n",
    "for t in range(epochs):\n",
    "    kld_weight = 0.0003*(t/20 if t/20 <= 1 else 1)\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, model.loss_function, optimizer, loss_output = loss_plot, recon_output = recon_plot, kld_output = kld_plot, weight = kld_weight)\n",
    "    test(test_dataloader, model, model.loss_function, weight = kld_weight)\n",
    "print(\"Done!\")\n",
    "\n",
    "# Loss plot\n",
    "plt.plot(range(1, epochs+1), loss_plot)\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch') \n",
    "plt.title('Training loss', fontsize=16)\n",
    "plt.xlim([0,epochs])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAETCAYAAADDIPqYAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAA28ElEQVR4nO3deXxTVf7/8ddN0nTfactSWkqxUHbKIi6IVBmRL4papEUFZ+y44fxcBhUERESmVB11RgdQUcYZcKQMw+iA6yCMKALaYllTtKWUvXShlKRL0uT+/ihEq01ToEma8nk+HjweSW7uzSe35b577rnnXEVVVRUhhBCiGRpPFyCEEKL9kpAQQgjhkISEEEIIhyQkhBBCOCQhIYQQwiEJCSGEEA5JSIh2adasWfTu3bvFf6+99toFb3/t2rX07t2bysrKVq/Tu3dv3n777Qv+zNY4cuQIvXv35pNPPnHp5wjRWjpPFyBEc6ZPn05GRob9+cyZM4mPj2f69On21zp37nzB27/22mvJyckhJCSk1evk5OTQtWvXC/5MIbyRhIRol+Li4oiLi7M/9/PzIyIigsGDB7fJ9iMiIoiIiDivddrqs4XwJnK6SXi1qVOn8vTTT5OZmUlKSgrPP/88ALt27eLee+9l2LBh9O/fnxtuuIFVq1bZ1/v56abU1FSWLVvGM888w4gRI0hJSWHmzJkYjUb7Oj893fTaa69x2223sX79em644QYGDBhAWloaO3bsaFLfxx9/zIQJExg4cCCTJk1iw4YN9O7dm+3bt7f6OxYUFPDb3/6WESNGMGLECJ544gnKy8vty2tqapgzZw5XX301AwcO5NZbb+Wzzz5r9XIhWiIhIbze2rVriY2N5dVXX+XGG2/k2LFjTJs2jYCAAP785z+zePFiEhISeOaZZygoKHC4nTfeeIPq6mpefvllHn30UT788EOWLl3q8P0HDx7k1Vdf5Xe/+x2vvfYa9fX1PPLIIzQ0NACwefNmHnvsMQYMGMDixYu58sormTFjxnl9N4PBQHp6OhaLhezsbGbPnk1ubi533XUXNTU1ADz//PNs27aNOXPm8MYbb5CYmMgjjzxCUVFRq5YL0RI53SS8XmBgIHPnzsXHxweAL774gsGDB/PHP/7R/tqgQYO4/PLLyc3NpU+fPs1up3Pnzrz88ssoisLVV1/NN998w+bNm3niiSeafb/JZOKdd95h4MCBAFitVqZPn05BQQH9+/dnyZIlDB8+nEWLFgEwatQoTCYTK1eubPV3W7JkCRERESxbtgy9Xg9A//79uemmm/jXv/7F1KlTyc3N5aqrruLGG28EYOjQoXTq1MkeVs6WC9ESCQnh9eLi4uxhADB69GhGjx5NfX09BQUFHDx4kN27dwNgNpsdbmfAgAEoimJ/3rlzZwwGg8P363Q6+vfv3+T9ALW1tdTX17Nz505mzpzZZJ1x48adV0h8++23TJgwwR4QAL169aJ37958++23TJ06lSFDhrB69WpOnjzJmDFjuPbaa5k1a5b9/c6WC9ESCQnh9SIjI5s8t1qtZGdnk5OTg8ViIS4ujmHDhgHQ0qTH/v7+TZ4ritLi+/V6PRrNj2dszz222WycPn0am832i87xn9fqTHV1dbPrREZG2vtL5s6dS3R0NB988AGbNm1Co9EwduxYsrKyCAoKcrpciJZIn4TocJYuXcrq1at5/vnnycvL49NPP2Xu3LlurSEyMhIfH59fjMM4n3EZAKGhoVRUVPzi9fLycsLCwoDGK78efvhhPv/8cz7++GMefvhhNm3axIsvvtiq5UK0REJCdDj5+fn079+fG2+8kYCAAAC+/PJLoOWWRFvSarUMHjyYjRs3Nnn9888/P6/tDB06lM8//7zJabKioiK+//57UlJSsFqtTJgwgXfeeQeAnj178uCDDzJ48GCOHz/udLkQzsjpJtHhDBgwgGXLlrFy5UqSkpLYvXs3ixcvRlEU6urq3FbHQw89xG9+8xvmzp3LuHHjyM/Pt/dH/PQ0VUseeOABMjIyuPfee/n1r3/NmTNn+NOf/kS3bt245ZZb0Gq1DBw4kMWLF+Pr60vPnj3ZuXMneXl5PPvss06XC+GMhITocO677z7Kysr4y1/+Qn19PT169ODpp59m/fr1fPfdd26r44orruCFF15g8eLFvP/++/Tt25cZM2awaNEiewvHmf79+/O3v/2Nl19+mUceeQR/f39Gjx7NE088Ye9PmDt3LgEBAbz++utUVFTQrVs3Zs6cye23396q5UK0RJHblwrhGhs2bCAuLo6kpCT7azk5OcyfP5/t27ef15QgQniKtCSEcJFNmzbx1VdfMWPGDLp06UJRURGvvPIKN998swSE8BrSkhDCRUwmEy+99BKff/45FRUVREdHc9NNN/HQQw81GfcgRHsmISGEEMIhuQRWCCGEQxISQgghHPKqjuu8vDxPlyCEEF5p6NChF7SeV4UEXPgXdSeDwUBycrKny3BK6mxbUmfb8YYawXvqvJg/sOV0kxBCCIckJIQQQjgkISGEEMIhCQkhhBAOSUgIIYRwSEJCCCGEQxISQgghHPK6kFiwbh8L1u3zdBlCCHFJ8LrBdAUnqrFYbZ4uQwghLgle15LQahQabDJxrRBCuIPXhYROo2CVkBBCCLfwupDQajQ0WCUkhBDCHbwuJKQlIYQQ7uN1IaHVKjTYpONaCCHcwetCQicd10II4TZeFxJajSJ9EkII4SZeFxI+Go30SQghhJt4XUg09klISAghhDu4ZMS1zWZj/vz57N+/H71ez8KFC4mPj7cv37hxI4sXL0an05GWlsbkyZMBuOWWWwgODgYgNjaWRYsW/bJgjYJVOq6FEMItXBISGzZswGw2k5OTQ35+PtnZ2SxduhQAi8XCokWLWLNmDf7+/kyZMoUxY8YQEhICwIoVK1rctoy4FkII93HJ6aa8vDxGjRoFwODBg9mzZ499WVFREXFxcYSGhqLX6xk6dCi5ubkUFBRQW1vLPffcw7Rp08jPz2922zJOQggh3MclLQmj0UhQUJD9uVarpaGhAZ1Oh9FotJ9SAggMDMRoNOLn50dmZia33347Bw8e5N577+WTTz5Bp2taYtWpSiwNNgwGgytKbxN1dXXtur5zpM62JXW2HW+oEbynzovhkpAICgrCZDLZn9tsNvvB/ufLTCYTwcHBJCQkEB8fj6IoJCQkEBYWRllZGV26dGmy7ZioKKzqaZKTk11RepswGAztur5zpM62JXW2HW+oEbynzry8vAte1yWnm1JSUti8eTMA+fn5JCUl2ZclJiZSUlJCVVUVZrOZ3NxchgwZwpo1a8jOzgagtLQUo9FIVFTUL7at1SjYVLDJKSchhHA5l7Qkxo4dy5YtW8jIyEBVVbKysli3bh01NTWkp6cza9YsMjMzUVWVtLQ0YmJimDRpEk899RRTpkxBURSysrJ+caoJwEerAGBVVTQorihfCCHEWS4JCY1Gw4IFC5q8lpiYaH+cmppKampqk+V6vZ6XXnrJ6ba1msbGj9Wm4qNtg2KFEEI45HWD6XSaxtaDXAYrhBCu53UhoT0bElaZv0kIIVzO60JCpz3XkpBR10II4WpeFxJaOd0khBBu43UhIX0SQgjhPl4YEmevbpI+CSGEcDnvCwnpkxBCCLfxupCwX90kp5uEEMLlvC4kpE9CCCHcx+tC4qcjroUQQriW14WEtCSEEMJ9vC4k7OMkrNJxLYQQruZ1ISEtCSGEcB/vCwmt9EkIIYS7eF1IyLQcQgjhPl4XEjr7OAnpkxBCCFfzupD4seNaWhJCCOFqXhcS56blkD4JIYRwPe8LibMtCYuEhBBCuJzXhcSPI66lT0IIIVzN60JCJ30SQgjhNt4XEtInIYQQbuN1ISHjJIQQwn28LiR0MgusEEK4jdeFhLQkhBDCfbwuJGTEtRBCuI/XhcS5loRFrm4SQgiX87qQ0Mk9roUQwm28LiSkT0IIIdzHJSFhs9mYN28e6enpTJ06lZKSkibLN27cSFpaGunp6axevbrJsoqKCkaPHk1RUVGz21YUBZ1GkT4JIYRwA5eExIYNGzCbzeTk5DBjxgyys7PtyywWC4sWLWL58uWsWLGCnJwcysrK7MvmzZuHn59fi9vXahRpSQghhBu4JCTy8vIYNWoUAIMHD2bPnj32ZUVFRcTFxREaGoper2fo0KHk5uYC8Pzzz5ORkUF0dHSL29dpFKzScS2EEC6nc8VGjUYjQUFB9udarZaGhgZ0Oh1Go5Hg4GD7ssDAQIxGI2vXriUiIoJRo0bx5ptvOty2wWBAQaWsogKDweCK8i9aXV1du63tp6TOtiV1th1vqBG8p86L4ZKQCAoKwmQy2Z/bbDZ0Ol2zy0wmE8HBwaxYsQJFUdi6dSsGg4GZM2eydOlSoqKimmw7OTkZvc8RgkPDSE5OdkX5F81gMLTb2n5K6mxbUmfb8YYawXvqzMvLu+B1XRISKSkpbNq0ifHjx5Ofn09SUpJ9WWJiIiUlJVRVVREQEEBubi6ZmZmMGzfO/p6pU6cyf/78XwTEOVqNIpfACiGEG7gkJMaOHcuWLVvIyMhAVVWysrJYt24dNTU1pKenM2vWLDIzM1FVlbS0NGJiYs6vaI0iU4ULIYQbuCQkNBoNCxYsaPJaYmKi/XFqaiqpqakO11+xYkWL29dppSUhhBDu4HWD6aBxJli5BFYIIVzPaUicPHmSwsJCiouLmT17drvoyZc+CSGEcA+nITFz5kzKy8t55ZVXuOqqq8jKynJHXS3SaRQaZMS1EEK4nNOQaGhoYPjw4VRXV/N///d/2NrBwVlaEkII4R5OQ+LcNBrDhg1j27ZtWK1Wd9TVIp1GkanChRDCDZyGRHZ2NgkJCdx3331UVlby4osvuqOuFklLQggh3MNpSERHR3PddddRXV1NcXExGo3nL4jSaTXSJyGEEG7g9Ij/+OOPs3fvXl544QV8fHyYN2+eO+pqkU5aEkII4RZOQ6K6uprU1FRKS0u57777MJvN7qirRTJVuBBCuEerOq6XL19O3759KSwsbDI5n6dIS0IIIdyjVeMkKioqmD59Otu3b2f+/PluKKtlWo1G5m4SQgg3cDp3U0pKCtXV1eTk5NCjRw8GDhzojrpaJC0JIYRwD6ctiZdeeom1a9ei0+l4//33m9yK1FO0WgWLXN0khBAu57Ql8e2337Jq1SoA7r77biZPnuzyopyRloQQQrhHq6blODcVh6qqKIri8qKc0UmfhBBCuIXTlsT48eOZMmUKgwYNYteuXYwfP94ddbVIWhJCCOEeTkPinnvu4eqrr+bAgQNMmjSpya1IPUWrlXESQgjhDg5D4qWXXvrFqaV9+/YB8Pvf/961VTnR2JKQjmshhHA1hyHRs2dPd9ZxXmTEtRBCuIfDkLj11lvdWcd50WkU6bgWQgg38PyUrhdAq9FIx7UQQriBV4aE3L5UCCHcw+nVTcePH2f9+vXU19fbX/vd737n0qKc0WkVbCrYbCoajefHbQghREfltCXxyCOPYDQa6dSpk/2fp+nOBoNVlVNOQgjhSk5bEoGBgTz22GPuqKXVtGfvjme1qfhoPVyMEEJ0YE5D4rLLLuPDDz8kOTnZPm4iISHB5YW15FxLQi6DFUII13IaEgaDAYPBYH+uKAp///vfXVqUM9pzp5vkMlghhHAppyGxYsUKTp06xeHDh4mNjSUiIsIddbVIp20MCZkuXAghXMtpx/XHH39MRkYGr7/+Ounp6XzwwQfuqKtF9paEnG4SQgiXctqSeOedd1i7di2BgYEYjUbuvvtuJk6c6I7aHPI523EtfRJCCOFaTkNCURQCAwMBCAoKwtfX1+lGbTYb8+fPZ//+/ej1ehYuXEh8fLx9+caNG1m8eDE6nY60tDQmT56M1Wpl7ty5FBcXo9VqWbRoEXFxcc1uX/okhBDCPZyGRFxcHNnZ2QwbNozc3FyHB+6f2rBhA2azmZycHPLz88nOzmbp0qUAWCwWFi1axJo1a/D392fKlCmMGTOGnTt3ArBq1Sq2b9/OokWL7Ov8omjtuaubpE9CCCFcyWlIZGVlkZOTw9dff01iYiIzZsxwutG8vDxGjRoFwODBg9mzZ499WVFREXFxcYSGhgIwdOhQcnNzufHGG7n22msBOHbsWIuD9qRPQggh3MNhSOzevZsBAwawbds24uPj7aeLtm/fztVXX93iRo1GI0FBQfbnWq2WhoYGdDodRqOR4OBg+7JzfR0AOp2OmTNn8t///pdXX3212W0bDAZOHDMB8ENhEQ2Vzk9/uVtdXV2Ty4bbK6mzbUmdbccbagTvqfNiOAyJrVu3MmDAAD788MNfLHMWEkFBQZhMJvtzm82GTqdrdpnJZGoSGs8//zyPP/44kydP5sMPPyQgIKDJtpOTkzmilgKldI9PIDk2tOVv6AEGg4Hk5GRPl+GU1Nm2pM624w01gvfUmZeXd8HrOgyJ++67D4CUlBRuv/12++utGUiXkpLCpk2bGD9+PPn5+U1ueZqYmEhJSQlVVVUEBASQm5tLZmYm77//PqWlpdx///34+/ujKApabfNzbvw44lr6JIQQwpUchsT69evZuHEj27dvZ9u2bQBYrVZ++OEHpk2b1uJGx44dy5YtW8jIyEBVVbKysli3bh01NTWkp6cza9YsMjMzUVWVtLQ0YmJi+NWvfsVTTz3FnXfeSUNDA7Nnz3Z4JZX0SQghhHs4DIlRo0YRFRVFVVWV/WCv0Wjo3r27041qNBoWLFjQ5LXExET749TUVFJTU5ssDwgI4M9//nPritbK3E1CCOEODkdch4aGcvnll/PMM89QWlrKiBEj+N///ofFYnFnfc3S/WQWWCGEEK7jdFqOmTNnEhUVBcDo0aOZM2eOy4tyRiuzwAohhFu06vall19+OQDDhw/H1g46i+03HWoHtQghREfmdDBdSEgIOTk5DB48mF27dtmn6PAke0tCpuUQQgiXctqSyM7OprCwkBdffJGioiKysrLcUVeLpONaCCHcw2lLoq6ujt/85jdNnnua3JlOCCHcw2lIPPbYYyiKgs1m48iRI8THx/Pee++5ozaHfrzHtfRJCCGEKzkNiZycHPvj6upq5s2b59KCWkMnfRJCCOEWrbq66Zzg4GAOHTrkqlpa7VyfhIyTEEII13LakkhPT0dRGg/KFRUVXHnllS4vyhkZJyGEEO7RqvtJ+Pn5AeDr69vifR7cxffsxH/1DdInIYQQruT0dNPcuXPp1q0b3bp1axcBARDk15htp2s9P0WIEEJ0ZE5bEgEBAWRlZZGQkIDm7FVF6enpLi+sJVqNQoifjmoJCSGEcCmnITFkyBCgsT+iPQkN8KGqxuzpMoQQokNzGhIajYbp06fbn7/00ksuLai1wvz1crpJCCFczGFI/POf/2TNmjUUFRWxefNmoPGmQw0NDcyYMcNtBToS6u9DlYSEEEK4lMOQmDhxIldccQVvvPEGDzzwANDYqoiMjHRbcS0JDfDh2OlaT5chhBAdmsOrm/R6PbGxsTz11FNotVp8fX1Zu3YtZWVl7qzPoVB/H07XSEtCCCFcyeklsI8//jh79uzhhRdewMfHp11MywEQdvZ0k6rKgDohhHAVpyFRXV3Nddddx4kTJ7jvvvswm9vHFUVhAT5YbSoms9XTpQghRIflNCQsFgvLly+nX79+FBYWYjKZ3FGXU6H+PgByGawQQriQ05B48sknqaio4MEHH2T79u3Mnz/fDWU5F+qvB2TUtRBCuJLTcRJDhw6lR48eGI1GxowZ446aWuVcS0I6r4UQwnWchsT8+fPZvHkz0dHRqKqKoiisWrXKHbW1KCzgbEhIS0IIIVzGaUjs2rWLDRs22Odtai/sfRISEkII4TJOj/zx8fHU19e7o5bzIi0JIYRwPactiePHjzNmzBji4+MB2s3pJn8fLT5ahSrpkxBCCJdxGhLtZUK/n1MUhVCZ5E8IIVzKaUhotVqysrIoKiqiR48ePPXUU+6oq1VC/XWcrpVxEkII4SqtujPdxIkTee+997j11luZM2eO043abDbmzZtHeno6U6dOpaSkpMnyjRs3kpaWRnp6OqtXrwYaB+098cQT3HHHHUyaNInPP//c6eeEBUhLQgghXMlpSNTX13PdddcREhLC9ddfT0NDg9ONbtiwAbPZTE5ODjNmzCA7O9u+zGKxsGjRIpYvX86KFSvIycmhrKyM//znP4SFhfGPf/yDZcuW8dxzzzn9nFB/H+mTEEIIF3IaElarlf379wOwf/9+FEVxutG8vDxGjRoFwODBg9mzZ499WVFREXFxcYSGhqLX6xk6dCi5ubmMGzeORx55xP4+rVbr9HPC/H2kJSGEEC7ktE9i7ty5zJ49m7KyMqKjo1v1F77RaCQoKMj+XKvV0tDQgE6nw2g0EhwcbF8WGBiI0WgkMDDQvu7DDz/Mo48+2uy2DQaD/bG17gyVxromr7UHdXXtr6bmSJ1tS+psO95QI3hPnRfDaUj06tWL5557jr59+7JhwwZ69erldKNBQUFNJgK02WzodLpml5lMJntoHD9+nIceeog77riDm266qdltJycn2x8nHP2eGkM1lyX1RqdtP4P9DAZDkzrbK6mzbUmdbccbagTvqTMvL++C123V/SR27twJQHFxMbNmzXK60ZSUFPstT/Pz80lKSrIvS0xMpKSkhKqqKsxmM7m5uQwZMoTy8nLuuecennjiCSZNmtSq4sP8ZUCdEEK4ktOWRGlpKVOmTAHg3nvvZerUqU43OnbsWLZs2UJGRgaqqpKVlcW6deuoqakhPT2dWbNmkZmZiaqqpKWlERMTw8KFC6murmbJkiUsWbIEgGXLluHn5+fwc8IDG2eCraq1EBnk26ovLIQQovWchgQ0tiASEhI4dOgQNpvN6fs1Gg0LFixo8lpiYqL9cWpqKqmpqU2Wz507l7lz57amHLvwgMaQqDSZSYw6r1WFEEK0gtOQmD17No8++igVFRVER0fz7LPPuqOuVokI/DEkhBBCtD2nITFo0CBWrlzJ0aNH6d69u/0qpPbgXEickpAQQgiXcBoSn376KUuXLsVqtTJu3DgURWH69OnuqM0p++kmuYWpEEK4hNOrm/7617+yevVqwsLCmD59Ohs2bHBHXa3ir9fi76Ol0ighIYQQruA0JDQaDXq9HkVRUBQFf39/d9TVahGBemlJCCGEizgNiWHDhjFjxgxKS0uZN28eAwYMcEddrRYe6CN9EkII4SJO+yR+//vfs3nzZpKTk+nZs+cvLl31tIhAXyplkj8hhHAJhy2JhoYGPvvsM7Zt28Y111zDb3/7WwYMGOBwTiVPiQiQloQQQriKw5bE448/jlarpaysjMLCQmJjY5kzZw7Tpk1zZ31OhQfqZZyEEEK4iMOQOHToEGvXrsVsNpOWloaPjw9///vfm4ycbg8iAvQY6xuob7Diq3M+vbgQQojWcxgS56b61uv12Gw2li9fTlhYmLvqajX7/E01FmJCJCSEEKIttWp+7cjIyHYZECBTcwghhCs5bEkUFhYyY8YMVFW1Pz7npZdecktxrSFTcwghhOs4DIk//elP9scZGRnuqOWCnAuJCgkJIYRocw5DYsSIEe6s44Kdm7/plIy6FkKINtd+7vl5gcICGu9OJ30SQgjR9rw+JHy0GkL8dNInIYQQLuD1IQEQGSRTcwghhCt0iJAID/Ch0lTv6TKEEKLD6RAh0SMykP0nzqCqqqdLEUKIDqVDhMSIhAjKjWaKyoyeLkUIITqUDhESl/eMBGDbgUoPVyKEEB1LhwiJHpEBRAf78k2xhIQQQrSlDhESiqJwec9IthdXSL+EEEK0oQ4REtDYL1FaXU9JRY2nSxFCiA6jw4TEyIQIAL74vszDlQghRMfRYUKiV3QQQ+LC+MumQs7UycA6IYRoCx0mJBRFYf5N/Sg7U89fNhZ6uhwhhOgQOkxIAAzqHsbtQ2NZvqWYk9V1ni5HCCG8nktCwmazMW/ePNLT05k6dSolJSVNlm/cuJG0tDTS09NZvXp1k2U7d+5k6tSpF/zZmaMSsFhVPi84ecHbEEII0cglIbFhwwbMZjM5OTnMmDGD7Oxs+zKLxcKiRYtYvnw5K1asICcnh7Kyxs7mZcuWMXfuXOrrL3wept4xwXQL8+dzQ+lFfw8hhLjUuSQk8vLyGDVqFACDBw9mz5499mVFRUXExcURGhqKXq9n6NCh5ObmAhAXF8drr712UZ+tKArXJ0fzVWE5tWbrRW1LCCEudS4JCaPRSFBQkP25VquloaHBviw4ONi+LDAwEKOxcc6lG264AZ3O4c3yWu265BjqLDa2FJZf9LaEEOJSdvFH5GYEBQVhMpnsz202m/3g//NlJpOpSWg4YzAYnL4n1Krir1NYs3U/3RT3T9VRV1fXqjo9TepsW1Jn2/GGGsF76rwYLgmJlJQUNm3axPjx48nPzycpKcm+LDExkZKSEqqqqggICCA3N5fMzMxWbzs5OblV77umdw27j1a3+v1tyWAweORzz5fU2bakzrbjDTWC99SZl5d3weu6JCTGjh3Lli1byMjIQFVVsrKyWLduHTU1NaSnpzNr1iwyMzNRVZW0tDRiYmLavIYRCZF8ureU46dr6RLq3+bbF0KIS4FLQkKj0bBgwYImryUmJtofp6amkpqa2uy6sbGxv7gs9kKM6NE4Tce3B09x8yAJCSGEuBAdajDdTyV3CSZQr+VbmT5cCCEuWIcNCZ1WQ0p8ON8elJAQQogL1WFDAmB4jwj2l57hdK1M+CeEEBeiQ4fEsB7hqCrklUhrQgghLkSHDokh3cMJ9tXxl42FWKw2T5cjhBBep0OHhL9ey6K0Aew4VEX2xwWeLkcIIbxOhw4JgAkDu3L3FfG8/VUx+45Ve7ocIYTwKh0+JAAeG5uEXqthde5hT5cihBBe5ZIIibAAPb/qF8P7+Uepb5CZYYUQorUuiZAAmDysO1U1Fjbsk5sRCSFEa10yIXFVr050CfVjTZ6cchJCiNa6ZEJCq1G4oV9nth6owNwgl8MKIURrXDIhATCyZwR1Fhu7jlR5uhQhhPAKl1RIjEiIBGC7TPonhBCtckmFRESgnqSYIAkJIYRopUsqJAAuT4gk72AlDTJNhxBCOHXphUTPCExmK7uPnvZ0KUII0e655M507dmIhMY71t265GsiAvX84Zb+3DigCwAWq40Tp+uIDfdHUZQL2v6OQ6f4aG8VaWHV9OkcfMHb+blP9pzgyKkaEqOD2HaggpPV9WTdOgB/vZbjp2vJ+fYwu46cZmBsKJcnRDIkLgw/H22bfLYQ4tJ1yYVEdLAfr04ZwoEyI5v2l/Hguzu4rk80Go3CN8WVnK61cEXPSB4bm8TwHuEOD/JlZ+rZeqCCY1W1hAf4EB6gp6jMxB8/24/VpvJW7pfEhvtzfXIMY/vGMCIhAh/t+TfcbDaV7E8KeHPzAftrOo2CVVWxqSqjk6KY9a/dWGw2ekQGsmn/SVT1B3x1Gp5PG8jEwV3J/riAkooabk3pxnV9otE5qKOkwkRJRQ1JMcH4aBV0Wg2h/j7nXTOAqqq89Nn37D12mj/cOoCwAB+2FFZQa7ESE+zLiISINgtQIYTrXHIhAXDzoK4APHhtIos+KuCL78vQaRSuS44mITKQd74+yOQ3ttIjMoB+3UKJCvLl6l6dCAvw4eM9J/jyhzK+LzU2u+2xfWOYnORDhSacDYZS3vvmEO98fZAgXx0je0YQFxGIxWrj24OVnKlrIH14d2otVj7de4IGq0psuD/zb+5HUkwwdRYrv1+dz0e7T3DXyDh+N+YyisqM9O0Swj++OcSLn+7ng/xjjOwZwQtpg4iLDOB0rYXcg5Us/V8RT/5rF1sKy/ln3hGCfXV8svcE3SP8mTCwKzsPV2EymZhQ5ku3cH92Hz3NW18ewGJV7d9Fq1F48obejOwZyWsbf8Bfr6Nf1xAAAvRaekUHERnoi69Og16nITxAj79eS53FysIP97Fy2yF0GoUb//wlqqpSXddg33afzsH8+soejEqKYv3OY3x3qAofnYZrk6K4dUg3NBoJECHaA0VVVdX529qHvLw8hg4d6vLPMdU38PGeE/xn5zGOVNZworqOGnPjnE96nYbLEyK4MrETV/WKpGdUEKdrLVQazVhsNgbHhrF/fwHJyckA1JqtfPlDGV98X8bXRRWUnalHVVUGdQ9Dq1H48odytBqFq3t1IiJQz+bvyzhT30Bq72gOVpgoOHGGOeOT+e2ohCZ/eauqyrwP9qLVKMwen4xe17R1UGkyc/NfvuLIqVpuHdKNFyYNZFPBSRZvKmTnkdP06RxMXV0dB6t+vGtfWkostw7pRnGFCZtN5euicj7dWwpAZKAeH62GE9V1DvebVqOQGBXI4cpaai1W7h/dk/Rh3Xl23T6C/XRMGRFHTIgfOw6d4q0vDzQJ2oROgdRZrBw/XUdylxBUVcVfr+Xd315OSdEP9v3ZnhkMBqmzjXhDjeA9dV7MsVNCohXMDTa2HqjgTJ2F0UlRBPu1fArmfH5xDlfW4OujITrYD2g8jfXc+n3sO16NRoFHr09i/Nk+k/NVeNLI+l3HePDaRHx1jf0TqqpiMlsJ8tVhMBgI75rA6VoLAXot3SMCmqyvqiortpVQWl3H/aMTCfHzobrOgk6jUF3bQOFJI9V1FswNNuobrBw5Vcvuo6fpHh7Ajf07c0VipMNTSqqq8t3hKrYWVTCmdzR9u4Zgs6n8a8cR3vn6IBGBer4qLOeOEXHc1UfnFf8RveWA4Q11ekON4D11Xsyx85I83XS+9DoNo5OiXLLtnx+Yo4J9eXXKkDbZdq/oIB69PqnJa4qiEOT744+9c6gfnUP9ml1fURSmXdGjyWshZwMyQK9zuF5rKIpCSlw4KXHh9tc0GoXbh3Xn9mHdAVj0kYE3Nh8gKagzXvD/UIgO6ZK7BFZ4j9//KonEqED+tqMSL2rwCtGhSEiIdstXp+XeUT05cMrMNzJKXgiPkJAQ7drEwd0I9tXwztcHHb5HWhlCuI6EhGjX/PVaxl0WzKd7T7Dj0CkarDbW7TzGf/eVUmGsZ/q7eVyxaCNFZY1XSp2ps9hDQ1VVfig9w4e7jnO61tLs9lsTMKdrLKzfdQybzfVhpKqqTBkj2hXpuBbt3s19QvmipI60pV/TOcSP46cbL8PVKI2X3QbodUx7+xuG9wjn/fxjdA31I6lzMDsPV3GqpjEcukf488rkwaTEhaPRKFisNp5bv4//7DzGzHF9uKJnJF8WlnNZdBDDe0SgPTtOQ1VVHludz8aCk/xuzBkev6H3L+qrNVtZ+kUR0UqNvYO9wWqj4MQZlm8p5ssfyvnDLf35Vb/Ov1jXZlP569cH6dM5mKHx4TywMo/ichP/nn4VEYH6Nt2PNlvjFWU2s3tv4Xu4sob7V+TRr2sID1932S8u1vg5i9XG9+X19FHVX1wdV1JhwmK10Ss62JUlez2rTUWj0CYDViUkRLvXKVDHhhmjefmz7yk4Uc38m/uhAF8VljNpaCwaRSHjzW18vOcEd18Rz7HTdRSXm7guOYbhPcKJDPRl3gd7mPT6Vnx1GhI6BQJQcOIMiVGBPLV2d5PP89Vp0GkU+nQJYVh8OBsLTtI7Jpi/bCqkqtaMVlH45uApDlWYuC0llu8On2LP0WoA/lO4lTP1DRSdNGK22vD30dIl1I/7V+Zx08CuWKw2xg/owk2DuqKqKos+NrDsy2IAekQGUFJZg06j8GhOPr+9OoFP954gyFdHfGQgVyRG4qNVOFRZw+HKGjSKwg39O3OmroH/7T9JncWGXqsQFewLKJyuNbP/hJG6BiupvaNZub2E/+0vw1encMsPNu4aGY9NVfmqsJwB3UK5MjESnVZDrdlKbkklgb46YsP9iQry5WBFDV/sP8nwhAj6dQ2lus6CXqvBz0fLlsJy/pV3hMnDu3P52ZH0DVYbJZU11JqtTH93B6dMZgrLjKzZcYRBsWGk9onmmqQoys7Uc+RUDTcN6kqnIF9Kq+t46N0d5JacIr/Kh3kT+qIoCsXlJhZ9ZOC/hsZxO/eN6sntw2LRa7V0C/e3h/o5hytrOFZVy6DujqenKakw8ZeNhRhOVHNVr04kdw4hNMCH3jHB+Gg1bCwoJS6icb/XmBv4Z27j5dmm+gYGxoZyY/8uJOp/bPWdMpkJC/CxH5hVVWXvsWp+OHmGUyYLPaMCGdI9nNAAH/JKKtlYcJIxvaMZ1D2M41V1vPllEV8XVvDsxH6MuiyKI6dqOHmmnjqLFV+dln3Hq/l0zwlC/HXERQTyfekZjlXVYlNVRl0WxW+u6sGZugb+/d1RVmwtISbEl9uHdee2lG4X9f9Pxkm4gLdcO92R6jxcWYNepyEmpPnLck/XWPhoz3GKTho5UG7ixOk6fnNVD9JSYnk//yiVJjPX9o5m/4kzfHfoFFZV5ePdJzhRXceViZH89TfDmb5yB58XnCTIV0f/biFEB/vx8Z7j+Oq0/PH2gWzfd5CvjpiJDfcnKSaYpJhgru0dRYBex1Nrd/HlD+XotAql1fWM69cZs9XGxoKT3DUyDp1Gwz++OcSiWwdQ12Blzr/3ABCo12KxqpgdnILSazUOlwH4+WjQaTQY6xvQazU8OvYydhUd44uDNdRamrYogs6GwqHKGvvgUWgMzfqf3M2xZ6dADlaYCPLVcX3fGD7IP4ZNVVFV6BbmT7cwfwwnqjlzdoR9wNlBkV3D/Fn1zWE27j/JriNV/PTI4+ejIblLCIbj1SgoDOniy9eHariqVyQJnQL5Z+4R9DoNv76yBxUmM//YfqhJfV3D/FGAYH8ftArsOFRl3z+dgvRoNAq1Z79T1zB/Kk1mjlbV4qvTMKBbKPmHq2hwcDrx6l6d2H30NKdrLaTEhREfGUhuSSWHK2vx1SkMjA2jwmTmQJmJuIgArknqhKneyvYDFRw73XTwqV6nYWhcONuKK/j5kddHqxAd7Mex07XERwRwsKLmF7UkRgVitto4eqqWXtFB9hkcviosx3q2fo0C4wd0odxYz7YDlWgU+Oekzu1rMJ3NZmP+/Pns378fvV7PwoULiY+Pty/fuHEjixcvRqfTkZaWxuTJk52uAxISbU3qbFmt2cr6XccY0yeaTkG+QOMpm59OGXLyTB02W+N4k9bU2WC18cqG73nry2K6hPrxq36dmTWuj/0UmI9Wg6qq/O3rgwT7+TBhUBf0Wg3F5Sb7f/juEQHERQRQaTKzbucxwgJ8GD+gC5GBvtQ3WCkz1qOqEOrvQ9cwfyxWG1sKy4mPDKRXdBAGg4GuPXrx4a7j+GgVRveOYkdJFVuLyjlaVUtUsB+/6heDzaZy5FQthytriA7xJbVPNJ/uLeWb4koGdQ+j4Hg1n+0r5frkGLLTBvDxnhN8U1zJsapakmKCGBYfgU6r0L9bKIlRQU32w7m5z2KCfQkL0LPsywMcqqihb9cQ7rw8DkvFYb446UvOt4c4WlXL6KRo/nBrf/sfATsOneLIqVpqzQ38UGq0zwRwutbCmboGUvtEk9wlhNySSiqNZqy2xhH8NlXlaFUdof4+9O0SQlpKN6JD/DDWN1BaXccpk5l9xxsDbnRSFBsLTvLO1wcZ0SOCe69JYGh84wShqqqy7UAlq77ax5EaLYG+OobHh7O9uJLvDp0iLEBPn87B3DigC4O7hxEW4MP3pWf4dM8JPi84yXV9onkotRebvy/n6KlaQv0bAzciUE/2xwUUl5sY0zuahKhAfHUazA02YkL87JOGWm1qk9bTwXITn+07QUyIHylx4fZTeiUVJv6Vd4TRkcYLP3aqLvDpp5+qM2fOVFVVVb/77jv1gQcesC8zm83q9ddfr1ZVVan19fXqbbfdpp48ebLFdc7Jzc11Rbltbt++fZ4uoVWkzrZ1PnXabDYXVtKyttyfJ6vrXPJdflqjJ/eVM97yu3kxx06X9Enk5eUxatQoAAYPHsyePXvsy4qKioiLiyM0NBSAoUOHkpubS35+vsN1hOhoOsoMuI39H67VUfaVt3JJSBiNRoKCfmxearVaGhoa0Ol0GI1GgoN/vDIhMDAQo9HY4jo/ZTAYXFFym6qrq5M625DU2ba8oU5vqBG8p86L4ZKQCAoKwmQy2Z/bbDb7wf7ny0wmE8HBwS2u81NyDr3tSJ1tS+psO95QI3hPnXl5eRe8rksG06WkpLB582YA8vPzSUr6cZK5xMRESkpKqKqqwmw2k5uby5AhQ1pcRwghhGe4pCUxduxYtmzZQkZGBqqqkpWVxbp166ipqSE9PZ1Zs2aRmZmJqqqkpaURExPT7DpCCCE8yyUhodFoWLBgQZPXEhMT7Y9TU1NJTU11uo4QQgjPkrmbhBBCOCQhIYQQwiGvm5ZDCCHE+WtX03IIIYToGOR0kxBCCIckJIQQQjjkFfeTaM0MsZ5isViYPXs2R48exWw28+CDD9K5c2ceeOABevToAcCUKVMYP368ZwsFbrnlFvuUKLGxsTzwwAPMmjULRVG47LLLeOaZZ9BoPPt3w9q1a/n3v/8NQH19PQaDgVWrVrWb/blz507++Mc/smLFCkpKSprdf6tXr2bVqlXodDoefPBBxowZ49E6DQYDzz33HFqtFr1ez/PPP0+nTp1YuHAhO3bsIDCw8f4aS5YsaTJljrvr3Lt3b7M/5/a2Px977DHKy8sBOHr0KIMGDeKVV17x6P5s7jjUq1evtvn9bIsZBl2tNTPEesqaNWvUhQsXqqqqqpWVlero0aPV1atXq2+//baHK2uqrq5OnThxYpPX7r//fnXbtm2qqqrq008/rX722WceqMyx+fPnq6tWrWo3+/PNN99UJ0yYoN5+++2qqja//06ePKlOmDBBra+vV6urq+2PPVnnnXfeaZ+t9L333lOzsrJUVVXVjIwMtaKiwq21tVRncz/n9rg/z6mqqlJvvvlmtbS0VFVVz+7P5o5DbfX76RWnm1qaVdbTxo0bxyOPPGJ/rtVq2bNnD//73/+48847mT17Nkaj0YMVNiooKKC2tpZ77rmHadOmkZ+fz969exkxYgQA11xzDV9//bWHq/zR7t27KSwsJD09vd3sz7i4OF577TX78+b2365duxgyZAh6vZ7g4GDi4uIoKCjwaJ0vv/yyfX4hq9WKr68vNpuNkpIS5s2bR0ZGBmvWrHFrjc3V2dzPuT3uz3Nee+017rrrLqKjoz2+P5s7DrXV76dXhISjGWLbg8DAQIKCgjAajTz88MM8+uijDBw4kCeffJJ3332X7t27s3jxYk+XiZ+fH5mZmbz99ts8++yzPP7446g/uYdwYGAgZ86c8XCVP3rjjTd46KGHANrN/rzhhhuaTDrZ3P5zNMuxJ+uMjo4GYMeOHaxcuZJf//rX1NTUcNddd/Hiiy/y1ltv8Y9//MPtB9+f19ncz7k97k+AiooKtm7dym233Qbg8f3Z3HGorX4/vSIkWjtDrKccP36cadOmMXHiRG666SbGjh1L//79gcZ5rPbt2+fhCiEhIYGbb74ZRVFISEggLCyMiooK+3KTyURISIgHK/xRdXU1Bw4cYOTIkQDtcn8CTfpvzu0/R7Mce9pHH33EM888w5tvvklERAT+/v5MmzYNf39/goKCGDlypNtD4uea+zm31/35ySefMGHCBLTaxvtnt4f9+fPjUFv9fnpFSLTnGWLLy8u55557eOKJJ5g0aRIAmZmZ7Nq1C4CtW7fSr18/T5YIwJo1a8jOzgagtLQUo9HIVVddxfbt2wHYvHkzw4YN82SJdt9++y1XXnml/Xl73J8Affv2/cX+GzhwIHl5edTX13PmzBmKioo8/vv6wQcfsHLlSlasWEH37t0BOHjwIHfccQdWqxWLxcKOHTs8vl+b+zm3x/15rr5rrrnG/tzT+7O541Bb/X62nz/HW9CeZ4h9/fXXqa6uZsmSJSxZsgSAWbNmkZWVhY+PD506deK5557zcJUwadIknnrqKaZMmYKiKGRlZREeHs7TTz/Nyy+/TM+ePbnhhhs8XSYAxcXFxMbG2p/Pnz+f5557rl3tT4CZM2f+Yv9ptVqmTp3KHXfcgaqqPPbYY/j6uv7ubY5YrVb+8Ic/0KVLF/7f//t/AAwfPpyHH36Ym266icmTJ+Pj48PEiRO57LLLPFYnNP9zDgoKalf785zi4mJ74ELjBKae3J/NHYfmzJnDwoULL/r3U0ZcCyGEcMgrTjcJIYTwDAkJIYQQDklICCGEcEhCQgghhEMSEkIIIRzyiktghXCn7du38+ijj9KrVy/7a+Hh4bz66qsXtd1Zs2Yxfvz4JtfXC9HeSUgI0YyRI0fyyiuveLoMITxOQkKIVpo6dSoJCQkUFxejqiqvvPIKUVFRZGdn22+tO2HCBO6++24OHjzI3LlzsVgs+Pn52QMnJyeHt956C6PRyPz58xk4cKAnv5IQTklICNGMbdu2MXXqVPvz0aNHA41TxCxYsIB3332XN954g6uuuoojR46wevVqGhoauOOOOxg5ciR/+tOfuO+++7jmmmv46KOP7PNN9evXj+nTp7N27VrWrl0rISHaPQkJIZrR3OmmL774wj7pYEpKChs3bqRz584MGzYMRVHw8fFh0KBBFBUVUVxczJAhQwDsN0hav369fT6fTp06UVdX58ZvJMSFkaubhDgP5+5lsmPHDnr16kViYqL9VJPFYuG7774jPj6exMREdu/eDcB//vMfVqxYAWCfulkIbyEtCSGa8fPTTQB1dXX8+9//5p133sHf358XXniB8PBwvvnmG9LT07FYLIwbN45+/frx5JNPMm/ePJYuXYqfnx8vvvgie/fu9dC3EeLCyQR/QrTS1KlTmT9/PomJiZ4uRQi3kdNNQgghHJKWhBBCCIekJSGEEMIhCQkhhBAOSUgIIYRwSEJCCCGEQxISQgghHJKQEEII4dD/B7bQmIirWAobAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Reconstruction loss plot\n",
    "plt.plot(range(1, epochs+1), recon_plot)\n",
    "plt.ylabel('Reconstruction loss')\n",
    "plt.xlabel('Epoch') \n",
    "plt.title('Training loss', fontsize=16)\n",
    "plt.xlim([0,epochs])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# KLD plot\n",
    "plt.plot(range(1, epochs+1), kld_plot)\n",
    "plt.ylabel('KLD')\n",
    "plt.xlabel('Epoch') \n",
    "plt.title('Training loss', fontsize=16)\n",
    "plt.xlim([0,epochs])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to ./trained_models/VAE_MLP512_30_5_manual.pth\n"
     ]
    }
   ],
   "source": [
    "save_model = False\n",
    "model_name = \"VAE_MLP512_30_\"+str(latent_dim)+\"_manual.pth\"\n",
    "\n",
    "if save_model:\n",
    "    trained_root = \"./trained_models/\"\n",
    "    \n",
    "    model_path = trained_root + model_name\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    print(f\"Saved PyTorch Model State to {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For these sections, the CPU will be used\n",
    "device = 'cpu'\n",
    "model = AirfoilVAE(in_channels = in_channels,\n",
    "            latent_dim = latent_dim,\n",
    "            hidden_dims = hidden_dims).to(device)\n",
    "model_root = \"./trained_models/\"\n",
    "model_name = \"VAE_MLP512_30_\"+str(latent_dim)+\"_manual.pth\"\n",
    "\n",
    "model_path = model_root + model_name\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Making predictions on random airfoils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mu: [0.04884702 0.01198692 2.047626   0.6448984  0.20599924]\n",
      "std: [0.99070996 0.97070473 0.16915329 0.12806249 0.07576117]\n",
      "------ Comparison ------\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idxpred = np.random.randint(0, len(test_data))\n",
    "x, y = test_data[idxpred][0].to(device), test_data[idxpred][1].to(device)\n",
    "dummy = np.array([0, 0, 0, 0, 0, 0]) # Dummy variable to complete the dataset rows to 36 for plotting\n",
    "with torch.no_grad():\n",
    "    pred = model.forward(x)     # Returns [recons, input, mu, log_var]\n",
    "    reconstructed = denormalize_data(np.concatenate((pred[0].cpu().numpy(), dummy), axis=0),scaler)\n",
    "    original = denormalize_data(np.concatenate((pred[1].cpu().numpy(), dummy), axis=0),scaler)\n",
    "    plot1 = plt.subplot2grid((1,3), (0,0), colspan = 3)\n",
    "    print(f'mu: {pred[2].cpu().numpy()}')\n",
    "    print(f'std: {np.exp(0.5*pred[3].cpu().numpy())}')\n",
    "    print(\"------ Comparison ------\")\n",
    "    airfoil_plot(original, fig=plot1, label=\"Original\")\n",
    "    airfoil_plot(reconstructed, fig=plot1, label=\"Reconstructed\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Generating random airfoils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sampled = model.sample(1, 'cpu')\n",
    "dummy = np.array([0, 0, 0, 0, 0, 0]) # Dummy variable to complete the dataset rows to 36 for plotting\n",
    "with torch.no_grad():\n",
    "    sampled = model.sample(1, 'cpu')     # Returns [norm_coords] of an invented airfoil\n",
    "    invented = denormalize_data(np.concatenate((sampled[0].cpu().numpy(), dummy), axis=0),scaler)\n",
    "    airfoil_plot(invented, label=\"Invented\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fe0a3989b890fde71862de81e2f587f17cb49601957bca599f33cd6f45bc5793"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('pytorchML')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
