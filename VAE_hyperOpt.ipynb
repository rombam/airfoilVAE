{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Airfoil Aerodynamic Coefficients Prediction using ANN - Optimization of hyperparameters\n",
    "## 1. Bayesian Optimization (Ax)\n",
    "MLP-based surrogate model to infer aerodynamic coefficients.\n",
    "\n",
    "This notebook uses:\n",
    " - Bayesian Optimization methods with the Optuna library.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import functional as F\n",
    "from matplotlib import rc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from AirfoilVAE import AirfoilVAE\n",
    "from compute_fid import compute_fid\n",
    "\n",
    "\n",
    "plt.style.use('seaborn-whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "CUDA version: 11.1\n"
     ]
    }
   ],
   "source": [
    "# Library options\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "rc('font',**{'family':'sans-serif','sans-serif':['Helvetica']})\n",
    "rc('font',**{'family':'serif','serif':['Palatino']})\n",
    "rc('text', usetex=True)\n",
    "\n",
    "# Get CPU or GPU device for NN\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def airfoil_plot(airfoil_coords, fig=None, label=None, spacing='cosine', n_points=30):\n",
    "    \"\"\"\n",
    "    Returns a plot of an airfoil. Used to visualize output of the optimizer. \n",
    "    Assumes 15 points for upper surface and 15 points for lower surface, with cosine spacing.\n",
    "    NOTE: This function should be edited depending on the database.\n",
    "    Inputs:\n",
    "        - airfoil_coords: pandas DataFrame with airfoil coordinates and other parameters\n",
    "    Outputs:\n",
    "        - Plot of airfoil shape\n",
    "    \"\"\"\n",
    "    if fig==None:\n",
    "        fig = plt.subplot2grid((1,3), (0,0), colspan = 3)\n",
    "    \n",
    "    # X coordinates\n",
    "    points_per_surf = int(n_points/2)\n",
    "    if spacing == 'cosine':\n",
    "        x = list(reversed([0.5*(1-np.cos(ang)) for ang in np.linspace(0,np.pi,points_per_surf+2)]))\n",
    "        aux_x = list([0.5*(1-np.cos(ang)) for ang in np.linspace(0,np.pi,points_per_surf+2)[1:points_per_surf+1]])\n",
    "        [x.append(i) for i in aux_x]\n",
    "        x.append(1)\n",
    "    elif spacing == 'linear':\n",
    "        x = list(reversed(list(np.linspace(0,1,points_per_surf+2))))\n",
    "        aux_x = list(list(np.linspace(0,1,points_per_surf+2)[1:points_per_surf+1]))\n",
    "        [x.append(i) for i in aux_x]\n",
    "        x.append(1)    \n",
    "\n",
    "    # Y coordinates\n",
    "    y = []\n",
    "    origin = (airfoil_coords.iloc[0][0]+airfoil_coords.iloc[0][points_per_surf])/2\n",
    "    y.append(0)\n",
    "    [y.append(j) for j in airfoil_coords.iloc[0][0:points_per_surf].values.tolist()]\n",
    "    y.append(origin)\n",
    "    #aux_y = list(reversed(airfoil_coords.iloc[points_per_surf:n_points].values.tolist()))\n",
    "    aux_y = list(airfoil_coords.iloc[0][points_per_surf:n_points].values.tolist())\n",
    "    [y.append(k) for k in aux_y]\n",
    "    y.append(0)\n",
    "\n",
    "    # Airfoil plot     \n",
    "    fig.plot(x, y, label = label)\n",
    "    fig.set_xlim([-0.1,1.1])\n",
    "    fig.set_ylim([-0.2,0.3])\n",
    "    fig.set_ylabel('$y/c$')\n",
    "    fig.set_xlabel('$x/c$') \n",
    "    fig.set_title('Airfoil plot', fontsize=16)\n",
    "    fig.legend(frameon=True)\n",
    "    if fig==None:\n",
    "        plt.show()\n",
    "    return\n",
    "\n",
    "\n",
    "def torch_test_split(X, y = None, test_size=0.2, seed=1234):\n",
    "    \"\"\"\n",
    "    Returns a train and test set in PyTorch tensor format from a numpy array dataset.\n",
    "    Inputs:\n",
    "        - X: numpy array with input data. Each row is a training/testing sample and each column is a feature.\n",
    "        - y: numpy array with output data. Each row is a training/testing sample and each column is an output.\n",
    "        - test_size: proportion of the dataset to be used as test set.\n",
    "        - seed: random seed for reproducibility.\n",
    "    Outputs:\n",
    "        - training_data: PyTorch tensor with training data.\n",
    "        - test_data: PyTorch tensor with test data.\n",
    "    \"\"\"\n",
    "    X_train_0, X_test_0, y_train_0, y_test_0 = train_test_split(X, y, test_size=test_size, random_state=seed)\n",
    "    X_train = torch.from_numpy(X_train_0).float()\n",
    "    X_test = torch.from_numpy(X_test_0).float()\n",
    "    y_train = torch.from_numpy(y_train_0).float()\n",
    "    y_test = torch.from_numpy(y_test_0).float()\n",
    "    training_data = []\n",
    "    testing_data = []\n",
    "    for i in range(len(X_train)):\n",
    "        training_data.append((X_train[i], y_train[i]))\n",
    "    for i in range(len(X_test)):\n",
    "        testing_data.append((X_test[i], y_test[i]))\n",
    "    return training_data, testing_data\n",
    "\n",
    "def normalize_data (data, scaler):\n",
    "    \"\"\"\n",
    "    Normalizes neural network inputs and outputs.\n",
    "    Inputs:\n",
    "        - data: data to be normalized. [np.array / pd.DataFrame]\n",
    "        - scaler: pre-fitted scaler object.\n",
    "    Outputs:\n",
    "        - normalized data. [pd.DataFrame]\n",
    "    \"\"\"\n",
    "    if type(data) == pd.DataFrame:\n",
    "        data = data.to_numpy().reshape(-1,scaler.n_features_in_)\n",
    "    elif type(data) == np.ndarray:\n",
    "        data = data.reshape(-1,scaler.n_features_in_)\n",
    "    else:\n",
    "        raise(TypeError('Input data must be either a pd.DataFrame or a np.ndarray'))\n",
    "    norm_data = pd.DataFrame(data = scaler.transform(data), columns = scaler.feature_names_in_)\n",
    "    return norm_data\n",
    "\n",
    "def denormalize_data (data, scaler):\n",
    "    \"\"\"\n",
    "    Denormalizes neural network inputs and outputs.\n",
    "    Inputs:\n",
    "        - data: data to be denormalized. [np.array / pd.DataFrame]\n",
    "        - scaler: pre-fitted scaler object.\n",
    "    Outputs:\n",
    "        - denormalized data. [pd.DataFrame]\n",
    "    \"\"\"\n",
    "    if type(data) == pd.DataFrame:\n",
    "        data = data.to_numpy().reshape(-1,scaler.n_features_in_)\n",
    "    elif type(data) == np.ndarray:\n",
    "        data = data.reshape(-1,scaler.n_features_in_)\n",
    "    else:\n",
    "        raise(TypeError('Input data must be either a pd.DataFrame or a np.ndarray'))\n",
    "    denorm_data = pd.DataFrame(data = scaler.inverse_transform(data), columns = scaler.feature_names_in_)\n",
    "    return denorm_data\n",
    "\n",
    "def init_weights(m):\n",
    "    \"\"\"\n",
    "    Resets all the weights in a given model. Uses a normal distribution with varying standard deviation for each weight depending on the layer type.\n",
    "    To be applied to a PyTorch model object as model.apply(init_weights).\n",
    "    Obtained from: https://stackoverflow.com/questions/64699434/reset-model-parameters-and-weights-of-a-network-pytorch-for-cross-validation\n",
    "    \"\"\"\n",
    "    if isinstance(m, nn.Embedding):\n",
    "        nn.init.normal_(m.weight, mean=0.0, std=0.1) ## or simply use your layer.reset_parameters()\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.normal_(m.weight, mean=0.0, std=np.sqrt(1 / m.in_features))\n",
    "        if m.bias is not None: \n",
    "            nn.init.zeros_(m.bias)\n",
    "    if isinstance(m, nn.Conv1d):\n",
    "            nn.init.normal_(m.weight, mean=0.0, std=np.sqrt(4 / m.in_channels))\n",
    "            if m.bias is not None: \n",
    "                nn.init.zeros_(m.bias)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import data and optimize the model architecture\n",
    "A simple VAE will be taken as a baseline and its architecture (number of layers and units per hidden layer) will be optimized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of airfoil coordinates: 198\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yU_1</th>\n",
       "      <th>yU_2</th>\n",
       "      <th>yU_3</th>\n",
       "      <th>yU_4</th>\n",
       "      <th>yU_5</th>\n",
       "      <th>yU_6</th>\n",
       "      <th>yU_7</th>\n",
       "      <th>yU_8</th>\n",
       "      <th>yU_9</th>\n",
       "      <th>yU_10</th>\n",
       "      <th>...</th>\n",
       "      <th>yL_90</th>\n",
       "      <th>yL_91</th>\n",
       "      <th>yL_92</th>\n",
       "      <th>yL_93</th>\n",
       "      <th>yL_94</th>\n",
       "      <th>yL_95</th>\n",
       "      <th>yL_96</th>\n",
       "      <th>yL_97</th>\n",
       "      <th>yL_98</th>\n",
       "      <th>yL_99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>0.000828</td>\n",
       "      <td>0.001293</td>\n",
       "      <td>0.001860</td>\n",
       "      <td>0.002528</td>\n",
       "      <td>0.003298</td>\n",
       "      <td>0.004166</td>\n",
       "      <td>0.005133</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002838</td>\n",
       "      <td>0.002308</td>\n",
       "      <td>0.001830</td>\n",
       "      <td>0.001406</td>\n",
       "      <td>0.001036</td>\n",
       "      <td>0.000721</td>\n",
       "      <td>0.000462</td>\n",
       "      <td>0.000261</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.000029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>0.000529</td>\n",
       "      <td>0.000938</td>\n",
       "      <td>0.001461</td>\n",
       "      <td>0.002096</td>\n",
       "      <td>0.002840</td>\n",
       "      <td>0.003691</td>\n",
       "      <td>0.004645</td>\n",
       "      <td>0.005697</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001694</td>\n",
       "      <td>0.001380</td>\n",
       "      <td>0.001096</td>\n",
       "      <td>0.000843</td>\n",
       "      <td>0.000622</td>\n",
       "      <td>0.000433</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.000017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>0.000462</td>\n",
       "      <td>0.000829</td>\n",
       "      <td>0.001308</td>\n",
       "      <td>0.001905</td>\n",
       "      <td>0.002625</td>\n",
       "      <td>0.003470</td>\n",
       "      <td>0.004443</td>\n",
       "      <td>0.005543</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001289</td>\n",
       "      <td>0.001060</td>\n",
       "      <td>0.000852</td>\n",
       "      <td>0.000664</td>\n",
       "      <td>0.000497</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.000236</td>\n",
       "      <td>0.000420</td>\n",
       "      <td>0.000656</td>\n",
       "      <td>0.000943</td>\n",
       "      <td>0.001282</td>\n",
       "      <td>0.001669</td>\n",
       "      <td>0.002104</td>\n",
       "      <td>0.002581</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000372</td>\n",
       "      <td>-0.000303</td>\n",
       "      <td>-0.000240</td>\n",
       "      <td>-0.000185</td>\n",
       "      <td>-0.000137</td>\n",
       "      <td>-0.000096</td>\n",
       "      <td>-0.000062</td>\n",
       "      <td>-0.000035</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>-0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000213</td>\n",
       "      <td>0.000380</td>\n",
       "      <td>0.000593</td>\n",
       "      <td>0.000854</td>\n",
       "      <td>0.001162</td>\n",
       "      <td>0.001514</td>\n",
       "      <td>0.001910</td>\n",
       "      <td>0.002347</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000223</td>\n",
       "      <td>-0.000178</td>\n",
       "      <td>-0.000138</td>\n",
       "      <td>-0.000103</td>\n",
       "      <td>-0.000073</td>\n",
       "      <td>-0.000050</td>\n",
       "      <td>-0.000031</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>-0.000007</td>\n",
       "      <td>-0.000002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 198 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       yU_1      yU_2      yU_3      yU_4      yU_5      yU_6      yU_7  \\\n",
       "0  0.000052  0.000207  0.000466  0.000828  0.001293  0.001860  0.002528   \n",
       "1  0.000059  0.000235  0.000529  0.000938  0.001461  0.002096  0.002840   \n",
       "2  0.000051  0.000204  0.000462  0.000829  0.001308  0.001905  0.002625   \n",
       "3  0.000026  0.000105  0.000236  0.000420  0.000656  0.000943  0.001282   \n",
       "4  0.000024  0.000095  0.000213  0.000380  0.000593  0.000854  0.001162   \n",
       "\n",
       "       yU_8      yU_9     yU_10  ...     yL_90     yL_91     yL_92     yL_93  \\\n",
       "0  0.003298  0.004166  0.005133  ...  0.002838  0.002308  0.001830  0.001406   \n",
       "1  0.003691  0.004645  0.005697  ...  0.001694  0.001380  0.001096  0.000843   \n",
       "2  0.003470  0.004443  0.005543  ...  0.001289  0.001060  0.000852  0.000664   \n",
       "3  0.001669  0.002104  0.002581  ... -0.000372 -0.000303 -0.000240 -0.000185   \n",
       "4  0.001514  0.001910  0.002347  ... -0.000223 -0.000178 -0.000138 -0.000103   \n",
       "\n",
       "      yL_94     yL_95     yL_96     yL_97     yL_98     yL_99  \n",
       "0  0.001036  0.000721  0.000462  0.000261  0.000116  0.000029  \n",
       "1  0.000622  0.000433  0.000278  0.000157  0.000070  0.000017  \n",
       "2  0.000497  0.000351  0.000228  0.000130  0.000058  0.000015  \n",
       "3 -0.000137 -0.000096 -0.000062 -0.000035 -0.000016 -0.000004  \n",
       "4 -0.000073 -0.000050 -0.000031 -0.000017 -0.000007 -0.000002  \n",
       "\n",
       "[5 rows x 198 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define input dataset (.csv) name and path\n",
    "data_folder = './data/'\n",
    "dataset_name = 'NACA4Digit_Dataset15Point.csv'\n",
    "dataset_name = 'UIUC_dataset_198p.csv'\n",
    "\n",
    "# Import dataset\n",
    "airfoil_df = pd.read_csv(data_folder + dataset_name)\n",
    "try:\n",
    "    airfoil_df = airfoil_df.drop('Unnamed: 0', axis=1)    # Remove first column, counter\n",
    "except: pass\n",
    "num_coords = int(sum([1 for col in airfoil_df if col.startswith('y')]))\n",
    "print(f'Number of airfoil coordinates: {num_coords}')\n",
    "airfoil_df = airfoil_df.drop_duplicates(subset=['yU_1'], keep='first')    # Remove duplicate airfoil coordinates\n",
    "\n",
    "airfoil_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([32, 198]) torch.float32\n",
      "Shape of y: torch.Size([32, 198]) torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roman\\anaconda3\\envs\\pytorch19\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Data scaler fitting\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(airfoil_df)\n",
    "\n",
    "# Assemble a DataFrame with all the minimum and maximum values of each column\n",
    "# For normalization and de-normalization. Gives an idea of the bounds.\n",
    "scaler_bounds = pd.DataFrame(data = np.stack([scaler.feature_names_in_, scaler.data_min_, scaler.data_max_], axis=1), columns=['property', 'min', 'max'])\n",
    "\n",
    "# Data normalization\n",
    "airfoil_df_norm = normalize_data(airfoil_df, scaler)\n",
    "\n",
    "# Input and \"output\" features\n",
    "# Input and output features are both the same for this dataset.\n",
    "try:\n",
    "    X = airfoil_df_norm.drop(['Cl', 'Cd', 'Cm', 'ReynoldsNumber', 'MachNumber', 'alpha'], axis=1).values\n",
    "except: \n",
    "    X = airfoil_df_norm.values\n",
    "\n",
    "# Data tensors\n",
    "training_data, test_data = torch_test_split(X, X, test_size=0.2)\n",
    "\n",
    "# Data loaders\n",
    "batch_size = 32\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape} {y.dtype}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Architectural search\n",
    "First, we will look for the most optimal architecture for our VAE network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def generate_VAE(trial):\n",
    "    \"\"\"\n",
    "    Assemble a Variational Autoencoder with the parameters defined in the trial object.\n",
    "    Inputs:\n",
    "        - trial: trial object from Optuna. It generates the parameters for the network.\n",
    "    Outputs:\n",
    "        - model: VAE model with an architecture suggested by the trial object.\n",
    "    \"\"\"\n",
    "\n",
    "    # --- VAE parameters ---\n",
    "    device = 'cuda'\n",
    "    latent_dims = 4\n",
    "    in_channels = 198\n",
    "\n",
    "    model = AirfoilVAE(in_channels = in_channels,\n",
    "                       latent_dim = latent_dims,\n",
    "                       hidden_dims = hidden_dims).to(device)\n",
    "    hidden_dims = []\n",
    "    n_layers = trial.suggest_int('n_layers', 2, 3)\n",
    "    \n",
    "    for i in range(n_layers):\n",
    "        out_features = trial.suggest_int(f'n_units_l{i}', 128, 1024)\n",
    "        hidden_dims.append(out_features)\n",
    "\n",
    "    model = AirfoilVAE(in_channels = in_channels,\n",
    "                       latent_dim = latent_dims,\n",
    "                       hidden_dims = hidden_dims).to(device)\n",
    "    print(f\"Model architecture: {hidden_dims}\")\n",
    "    return model\n",
    "\n",
    "def train(dataloader, model, loss_fn, optimizer, epochs = 1):\n",
    "    \"\"\"\n",
    "    Train the input model on the input dataloader.\n",
    "    Inputs:\n",
    "        - Dataloader: a PyTorch DataLoader object.\n",
    "        - model: a PyTorch neural network model object.\n",
    "        - loss_fn: a PyTorch loss function object.\n",
    "        - optimizer: a PyTorch optimizer object.\n",
    "        - [Optional, int] epochs: number of epochs to train the model.\n",
    "    \"\"\"\n",
    "    for t in range(epochs):\n",
    "        kld_weight_coef = 5e-6\n",
    "        kld_weight = kld_weight_coef*(t/20 if t/20 <= 1 else 1)\n",
    "        model.train()\n",
    "        for batch, (X, y) in enumerate(dataloader):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            # Compute prediction error\n",
    "            pred = model(X)\n",
    "            loss = loss_fn(pred, weight = kld_weight)\n",
    "\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss['loss'].backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "def test(model): \n",
    "    \"\"\"\n",
    "    Calculate the input model FID with respect to the training dataset.\n",
    "    Inputs:\n",
    "        - model: a PyTorch neural network model object.\n",
    "    Outputs:\n",
    "        - fid: model FID with respect to the training dataset.\n",
    "    \"\"\"\n",
    "    sampled_norm = model.sample(10000, 'cpu', std_coef = 1)\n",
    "    sampled = denormalize_data(sampled_norm.detach().cpu().numpy(),scaler)\n",
    "    fid = compute_fid(airfoil_df.to_numpy(), sampled)\n",
    "    \n",
    "    print(f\"Model FID: {fid} \\n\")\n",
    "    return fid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objective function\n",
    "def objective(trial):\n",
    "    \"\"\"\n",
    "    Objective function. Takes a trial object that generates a MLP model architecture and outputs the test (validation) set RMSE.\n",
    "    \"\"\"\n",
    "    model = generate_VAE(trial)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0005, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)\n",
    "    train(train_dataloader, model, model.loss_function, optimizer, epochs = 5000)\n",
    "    fid = test(model)\n",
    "    return fid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 21:20:46,504]\u001b[0m A new study created in memory with name: no-name-ee389aad-90af-494a-868b-d2cee78194f8\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampler is TPESampler\n",
      "Pruner is HyperbandPruner\n"
     ]
    }
   ],
   "source": [
    "# Create a study object\n",
    "study = optuna.create_study(direction='minimize', pruner=optuna.pruners.HyperbandPruner())\n",
    "\n",
    "print(f\"Sampler is {study.sampler.__class__.__name__}\")\n",
    "print(f\"Pruner is {study.pruner.__class__.__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize the RMSE of the model\n",
    "study.optimize(objective, n_trials=100)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8770d59a9d935fca7c9271d867db5cf971b0248260eddbc084e8f23c1f4c1f23"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 ('pytorch19')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
